{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import  KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "## import 부분입니다\n",
    "df=pd.DataFrame()\n",
    "list=os.listdir('./df_total/')\n",
    "for list in list:\n",
    "    df1= pd.read_csv('./df_total/{}'.format(list))\n",
    "    df=pd.concat([df,df1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.8570016362148896\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['macc_x_mean', 'mgps_lat_std', 'e4acc_x_mean', 'temp_mean', 'bvp_std', 'hr_std'], axis=0)\n",
    "df = df[(df['action']!='sleep')&(df['action']!='recreation_etc')&(df['action']!='meal')&(df['action']!='hobby')]\n",
    "X = df.drop(['ts', 'action', 'actionOption', 'actionSub', 'actionSubOption', 'condition', 'conditionSub1Option', 'conditionSub2Option', 'place', 'emotionPositive', 'emotionTension', 'activity'], axis=1)\n",
    "y = df['action']\n",
    "\n",
    "\n",
    "## sleep은 추가적인 자료에 있고, 측정이 어렵기에 제거, recreation etc는 행위의 종류가 다양하여 제거 , 식사도 측정이 불가하다고 판단\n",
    "## 취미또한 한 테마안에 여러 활동이 포함되어 제거\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "\n",
    "## 수민님이 주신 scaler\n",
    "for col in X_train.columns:\n",
    "    scal = RobustScaler()\n",
    "    X_train[col] = scal.fit_transform(np.array(X_train[col]).reshape(-1, 1))\n",
    "    X_test[col] = scal.transform(np.array(X_test[col]).reshape(-1, 1))\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 300)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"정확도 : {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhm21\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\Users\\jhm21\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.39791\n",
      "[2]\tvalid_0's multi_logloss: 1.27324\n",
      "[3]\tvalid_0's multi_logloss: 1.17538\n",
      "[4]\tvalid_0's multi_logloss: 1.10901\n",
      "[5]\tvalid_0's multi_logloss: 1.04925\n",
      "[6]\tvalid_0's multi_logloss: 1.0014\n",
      "[7]\tvalid_0's multi_logloss: 0.962577\n",
      "[8]\tvalid_0's multi_logloss: 0.928847\n",
      "[9]\tvalid_0's multi_logloss: 0.900186\n",
      "[10]\tvalid_0's multi_logloss: 0.876551\n",
      "[11]\tvalid_0's multi_logloss: 0.857193\n",
      "[12]\tvalid_0's multi_logloss: 0.836384\n",
      "[13]\tvalid_0's multi_logloss: 0.821551\n",
      "[14]\tvalid_0's multi_logloss: 0.804983\n",
      "[15]\tvalid_0's multi_logloss: 0.794411\n",
      "[16]\tvalid_0's multi_logloss: 0.781348\n",
      "[17]\tvalid_0's multi_logloss: 0.773966\n",
      "[18]\tvalid_0's multi_logloss: 0.764362\n",
      "[19]\tvalid_0's multi_logloss: 0.753948\n",
      "[20]\tvalid_0's multi_logloss: 0.744613\n",
      "[21]\tvalid_0's multi_logloss: 0.732051\n",
      "[22]\tvalid_0's multi_logloss: 0.724366\n",
      "[23]\tvalid_0's multi_logloss: 0.719677\n",
      "[24]\tvalid_0's multi_logloss: 0.717006\n",
      "[25]\tvalid_0's multi_logloss: 0.714011\n",
      "[26]\tvalid_0's multi_logloss: 0.700583\n",
      "[27]\tvalid_0's multi_logloss: 0.70326\n",
      "[28]\tvalid_0's multi_logloss: 0.696985\n",
      "[29]\tvalid_0's multi_logloss: 0.696185\n",
      "[30]\tvalid_0's multi_logloss: 0.691962\n",
      "[31]\tvalid_0's multi_logloss: 0.683416\n",
      "[32]\tvalid_0's multi_logloss: 0.68354\n",
      "[33]\tvalid_0's multi_logloss: 0.684486\n",
      "[34]\tvalid_0's multi_logloss: 0.68011\n",
      "[35]\tvalid_0's multi_logloss: 0.676976\n",
      "[36]\tvalid_0's multi_logloss: 0.67478\n",
      "[37]\tvalid_0's multi_logloss: 0.688679\n",
      "[38]\tvalid_0's multi_logloss: 0.684099\n",
      "[39]\tvalid_0's multi_logloss: 0.681841\n",
      "[40]\tvalid_0's multi_logloss: 0.677611\n",
      "[41]\tvalid_0's multi_logloss: 0.669871\n",
      "[42]\tvalid_0's multi_logloss: 0.667965\n",
      "[43]\tvalid_0's multi_logloss: 0.678316\n",
      "[44]\tvalid_0's multi_logloss: 0.651633\n",
      "[45]\tvalid_0's multi_logloss: 0.657712\n",
      "[46]\tvalid_0's multi_logloss: 0.656174\n",
      "[47]\tvalid_0's multi_logloss: 0.657011\n",
      "[48]\tvalid_0's multi_logloss: 0.665088\n",
      "[49]\tvalid_0's multi_logloss: 0.651162\n",
      "[50]\tvalid_0's multi_logloss: 0.693215\n",
      "[51]\tvalid_0's multi_logloss: 0.677828\n",
      "[52]\tvalid_0's multi_logloss: 0.674661\n",
      "[53]\tvalid_0's multi_logloss: 0.672541\n",
      "[54]\tvalid_0's multi_logloss: 0.688407\n",
      "[55]\tvalid_0's multi_logloss: 0.657122\n",
      "[56]\tvalid_0's multi_logloss: 0.652983\n",
      "[57]\tvalid_0's multi_logloss: 0.656471\n",
      "[58]\tvalid_0's multi_logloss: 0.656608\n",
      "[59]\tvalid_0's multi_logloss: 0.653393\n",
      "[60]\tvalid_0's multi_logloss: 0.651939\n",
      "[61]\tvalid_0's multi_logloss: 0.657198\n",
      "[62]\tvalid_0's multi_logloss: 0.665234\n",
      "[63]\tvalid_0's multi_logloss: 0.725192\n",
      "[64]\tvalid_0's multi_logloss: 0.674798\n",
      "[65]\tvalid_0's multi_logloss: 0.764781\n",
      "[66]\tvalid_0's multi_logloss: 0.700175\n",
      "[67]\tvalid_0's multi_logloss: 0.673301\n",
      "[68]\tvalid_0's multi_logloss: 0.761083\n",
      "[69]\tvalid_0's multi_logloss: 0.694892\n",
      "[70]\tvalid_0's multi_logloss: 0.69678\n",
      "[71]\tvalid_0's multi_logloss: 0.685681\n",
      "[72]\tvalid_0's multi_logloss: 0.765938\n",
      "[73]\tvalid_0's multi_logloss: 0.718266\n",
      "[74]\tvalid_0's multi_logloss: 0.907803\n",
      "[75]\tvalid_0's multi_logloss: 0.723364\n",
      "[76]\tvalid_0's multi_logloss: 0.720351\n",
      "[77]\tvalid_0's multi_logloss: 0.731871\n",
      "[78]\tvalid_0's multi_logloss: 0.776012\n",
      "[79]\tvalid_0's multi_logloss: 0.718951\n",
      "[80]\tvalid_0's multi_logloss: 0.745902\n",
      "[81]\tvalid_0's multi_logloss: 0.723137\n",
      "[82]\tvalid_0's multi_logloss: 0.750832\n",
      "[83]\tvalid_0's multi_logloss: 0.721879\n",
      "[84]\tvalid_0's multi_logloss: 0.714193\n",
      "[85]\tvalid_0's multi_logloss: 0.721161\n",
      "[86]\tvalid_0's multi_logloss: 0.749083\n",
      "[87]\tvalid_0's multi_logloss: 0.744915\n",
      "[88]\tvalid_0's multi_logloss: 0.717821\n",
      "[89]\tvalid_0's multi_logloss: 0.746399\n",
      "[90]\tvalid_0's multi_logloss: 0.725586\n",
      "[91]\tvalid_0's multi_logloss: 0.732183\n",
      "[92]\tvalid_0's multi_logloss: 0.728386\n",
      "[93]\tvalid_0's multi_logloss: 0.719673\n",
      "[94]\tvalid_0's multi_logloss: 0.722372\n",
      "[95]\tvalid_0's multi_logloss: 0.747861\n",
      "[96]\tvalid_0's multi_logloss: 0.726474\n",
      "[97]\tvalid_0's multi_logloss: 0.733535\n",
      "[98]\tvalid_0's multi_logloss: 0.719104\n",
      "[99]\tvalid_0's multi_logloss: 0.738763\n",
      "[100]\tvalid_0's multi_logloss: 0.718903\n",
      "정확도:0.810557,정밀도:0.811000,    재현율:0.811000,f1:0.811000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm_wrapper = LGBMClassifier(n_estimators=100)\n",
    "evals=[(X_test,y_test)]\n",
    "lgbm_wrapper.fit(X_train, y_train, early_stopping_rounds=1000, eval_metric='logloss', eval_set=evals, verbose=True)\n",
    "preds = lgbm_wrapper.predict(X_test)\n",
    "## n_ estimator 가 200을 넘어가면 오히려 loss 가 증가하는 경향을 보여서 100으로 설정\n",
    "def get_clf_eval(y_test,pred = None,pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = round(precision_score(y_test, pred, average='micro'), ndigits=3)\n",
    "    recall = round(recall_score(y_test, pred, average='micro'), ndigits=3)\n",
    "    f1 = round(f1_score(y_test, pred, average='micro'), ndigits=3)\n",
    "    print('정확도:{0:,f},정밀도:{1:f},\\\n",
    "    재현율:{2:f},f1:{3:f}'.format(accuracy,precision,recall,f1),'\\n')\n",
    "# 모델 평가 지표 함수\n",
    "pred_proba = lgbm_wrapper.predict_proba(X_test)[:,1]\n",
    "get_clf_eval(y_test,preds,pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "list=os.listdir('./df_total/')\n",
    "for list in list:\n",
    "    df1= pd.read_csv('./df_total/{}'.format(list))\n",
    "    df=pd.concat([df,df1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.8545814016907554\n"
     ]
    }
   ],
   "source": [
    "## e4 결측치를 해당 ts m값으로 대체 - 그 후에도 결측치가 존재할경우 drop\n",
    "df[['e4acc_x_mean','e4acc_y_mean','e4acc_z_mean']] = df[['e4acc_x_mean','e4acc_y_mean','e4acc_z_mean']].fillna(df[['macc_x_mean','macc_y_mean','macc_z_mean']])\n",
    "df = df.dropna(subset=['macc_x_mean', 'mgps_lat_std', 'e4acc_x_mean', 'temp_mean', 'bvp_std', 'hr_std'], axis=0)\n",
    "df = df[(df['action']!='sleep')&(df['action']!='recreation_etc')&(df['action']!='meal')&(df['action']!='hobby')]\n",
    "X = df.drop(['ts', 'action', 'actionOption', 'actionSub', 'actionSubOption', 'condition', 'conditionSub1Option', 'conditionSub2Option', 'place', 'emotionPositive', 'emotionTension', 'activity'], axis=1)\n",
    "y = df['action']\n",
    "\n",
    "\n",
    "## sleep은 추가적인 자료에 있고, 측정이 어렵기에 제거, recreation etc는 행위의 종류가 다양하여 제거 , 식사도 측정이 불가하다고 판단\n",
    "## 취미또한 한 테마안에 여러 활동이 포함되어 제거\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "\n",
    "## 수민님이 주신 scaler\n",
    "for col in X_train.columns:\n",
    "    scal = RobustScaler()\n",
    "    X_train[col] = scal.fit_transform(np.array(X_train[col]).reshape(-1, 1))\n",
    "    X_test[col] = scal.transform(np.array(X_test[col]).reshape(-1, 1))\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 300)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"정확도 : {}\".format(accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "list=os.listdir('./To/df_total_2019/')\n",
    "for list in list:\n",
    "    df1= pd.read_csv('./To/df_total_2019/{}'.format(list))\n",
    "    df=pd.concat([df,df1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = df.dropna(subset=['macc_x_mean', 'mgps_lat_std', 'e4acc_x_mean', 'temp_mean', 'bvp_std', 'hr_std'], axis=0)\n",
    "df = df[(df['action']!='sleep')&(df['action']!='recreation_etc')&(df['action']!='meal')&(df['action']!='hobby')]\n",
    "X = df.drop(['ts', 'action', 'actionOption', 'actionSub', 'actionSubOption', 'condition', 'conditionSub1Option', 'conditionSub2Option', 'place', 'emotionPositive', 'emotionTension', 'activity'], axis=1)\n",
    "y = df['action']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.810126582278481\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## sleep은 추가적인 자료에 있고, 측정이 어렵기에 제거, recreation etc는 행위의 종류가 다양하여 제거 , 식사도 측정이 불가하다고 판단\n",
    "## 취미또한 한 테마안에 여러 활동이 포함되어 제거\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "\n",
    "## 수민님이 주신 scaler\n",
    "for col in X_train.columns:\n",
    "    scal = RobustScaler()\n",
    "    X_train[col] = scal.fit_transform(np.array(X_train[col]).reshape(-1, 1))\n",
    "    X_test[col] = scal.transform(np.array(X_test[col]).reshape(-1, 1))\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 250)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"정확도 : {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhm21\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\Users\\jhm21\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.4742\n",
      "[2]\tvalid_0's multi_logloss: 1.31578\n",
      "[3]\tvalid_0's multi_logloss: 1.19778\n",
      "[4]\tvalid_0's multi_logloss: 1.10438\n",
      "[5]\tvalid_0's multi_logloss: 1.03645\n",
      "[6]\tvalid_0's multi_logloss: 0.976351\n",
      "[7]\tvalid_0's multi_logloss: 0.91834\n",
      "[8]\tvalid_0's multi_logloss: 0.873231\n",
      "[9]\tvalid_0's multi_logloss: 0.837815\n",
      "[10]\tvalid_0's multi_logloss: 0.797401\n",
      "[11]\tvalid_0's multi_logloss: 0.764832\n",
      "[12]\tvalid_0's multi_logloss: 0.741291\n",
      "[13]\tvalid_0's multi_logloss: 0.72208\n",
      "[14]\tvalid_0's multi_logloss: 0.706463\n",
      "[15]\tvalid_0's multi_logloss: 0.689997\n",
      "[16]\tvalid_0's multi_logloss: 0.674885\n",
      "[17]\tvalid_0's multi_logloss: 0.659148\n",
      "[18]\tvalid_0's multi_logloss: 0.651343\n",
      "[19]\tvalid_0's multi_logloss: 0.643734\n",
      "[20]\tvalid_0's multi_logloss: 0.640057\n",
      "[21]\tvalid_0's multi_logloss: 0.627941\n",
      "[22]\tvalid_0's multi_logloss: 0.624075\n",
      "[23]\tvalid_0's multi_logloss: 0.618487\n",
      "[24]\tvalid_0's multi_logloss: 0.613318\n",
      "[25]\tvalid_0's multi_logloss: 0.608417\n",
      "[26]\tvalid_0's multi_logloss: 0.602764\n",
      "[27]\tvalid_0's multi_logloss: 0.603161\n",
      "[28]\tvalid_0's multi_logloss: 0.600819\n",
      "[29]\tvalid_0's multi_logloss: 0.592928\n",
      "[30]\tvalid_0's multi_logloss: 0.591848\n",
      "[31]\tvalid_0's multi_logloss: 0.594714\n",
      "[32]\tvalid_0's multi_logloss: 0.596995\n",
      "[33]\tvalid_0's multi_logloss: 0.597016\n",
      "[34]\tvalid_0's multi_logloss: 0.596527\n",
      "[35]\tvalid_0's multi_logloss: 0.59857\n",
      "[36]\tvalid_0's multi_logloss: 0.594394\n",
      "[37]\tvalid_0's multi_logloss: 0.598369\n",
      "[38]\tvalid_0's multi_logloss: 0.600074\n",
      "[39]\tvalid_0's multi_logloss: 0.604981\n",
      "[40]\tvalid_0's multi_logloss: 0.607858\n",
      "[41]\tvalid_0's multi_logloss: 0.610031\n",
      "[42]\tvalid_0's multi_logloss: 0.609158\n",
      "[43]\tvalid_0's multi_logloss: 0.610582\n",
      "[44]\tvalid_0's multi_logloss: 0.612566\n",
      "[45]\tvalid_0's multi_logloss: 0.617469\n",
      "[46]\tvalid_0's multi_logloss: 0.619191\n",
      "[47]\tvalid_0's multi_logloss: 0.621881\n",
      "[48]\tvalid_0's multi_logloss: 0.620269\n",
      "[49]\tvalid_0's multi_logloss: 0.621394\n",
      "[50]\tvalid_0's multi_logloss: 0.625308\n",
      "[51]\tvalid_0's multi_logloss: 0.626947\n",
      "[52]\tvalid_0's multi_logloss: 0.628972\n",
      "[53]\tvalid_0's multi_logloss: 0.632463\n",
      "[54]\tvalid_0's multi_logloss: 0.637047\n",
      "[55]\tvalid_0's multi_logloss: 0.640869\n",
      "[56]\tvalid_0's multi_logloss: 0.647785\n",
      "[57]\tvalid_0's multi_logloss: 0.650961\n",
      "[58]\tvalid_0's multi_logloss: 0.654264\n",
      "[59]\tvalid_0's multi_logloss: 0.65595\n",
      "[60]\tvalid_0's multi_logloss: 0.658152\n",
      "[61]\tvalid_0's multi_logloss: 0.664463\n",
      "[62]\tvalid_0's multi_logloss: 0.670267\n",
      "[63]\tvalid_0's multi_logloss: 0.67431\n",
      "[64]\tvalid_0's multi_logloss: 0.681738\n",
      "[65]\tvalid_0's multi_logloss: 0.684833\n",
      "[66]\tvalid_0's multi_logloss: 0.689412\n",
      "[67]\tvalid_0's multi_logloss: 0.694465\n",
      "[68]\tvalid_0's multi_logloss: 0.697915\n",
      "[69]\tvalid_0's multi_logloss: 0.702976\n",
      "[70]\tvalid_0's multi_logloss: 0.704776\n",
      "[71]\tvalid_0's multi_logloss: 0.706537\n",
      "[72]\tvalid_0's multi_logloss: 0.710614\n",
      "[73]\tvalid_0's multi_logloss: 0.71102\n",
      "[74]\tvalid_0's multi_logloss: 0.714467\n",
      "[75]\tvalid_0's multi_logloss: 0.716546\n",
      "[76]\tvalid_0's multi_logloss: 0.718384\n",
      "[77]\tvalid_0's multi_logloss: 0.722297\n",
      "[78]\tvalid_0's multi_logloss: 0.727002\n",
      "[79]\tvalid_0's multi_logloss: 0.730008\n",
      "[80]\tvalid_0's multi_logloss: 0.733204\n",
      "[81]\tvalid_0's multi_logloss: 0.738142\n",
      "[82]\tvalid_0's multi_logloss: 0.741466\n",
      "[83]\tvalid_0's multi_logloss: 0.74646\n",
      "[84]\tvalid_0's multi_logloss: 0.754295\n",
      "[85]\tvalid_0's multi_logloss: 0.757001\n",
      "[86]\tvalid_0's multi_logloss: 0.757965\n",
      "[87]\tvalid_0's multi_logloss: 0.762219\n",
      "[88]\tvalid_0's multi_logloss: 0.76855\n",
      "[89]\tvalid_0's multi_logloss: 0.767868\n",
      "[90]\tvalid_0's multi_logloss: 0.769999\n",
      "[91]\tvalid_0's multi_logloss: 0.772611\n",
      "[92]\tvalid_0's multi_logloss: 0.773644\n",
      "[93]\tvalid_0's multi_logloss: 0.779211\n",
      "[94]\tvalid_0's multi_logloss: 0.78127\n",
      "[95]\tvalid_0's multi_logloss: 0.78667\n",
      "[96]\tvalid_0's multi_logloss: 0.788767\n",
      "[97]\tvalid_0's multi_logloss: 0.791007\n",
      "[98]\tvalid_0's multi_logloss: 0.794089\n",
      "[99]\tvalid_0's multi_logloss: 0.797898\n",
      "[100]\tvalid_0's multi_logloss: 0.797898\n",
      "정확도:0.852321,정밀도:0.852000,    재현율:0.852000,f1:0.852000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm_wrapper = LGBMClassifier(n_estimators=100)\n",
    "evals=[(X_test,y_test)]\n",
    "lgbm_wrapper.fit(X_train, y_train, early_stopping_rounds=1000, eval_metric='logloss', eval_set=evals, verbose=True)\n",
    "preds = lgbm_wrapper.predict(X_test)\n",
    "## n_ estimator 가 200을 넘어가면 오히려 loss 가 증가하는 경향을 보여서 100으로 설정\n",
    "def get_clf_eval(y_test,pred = None,pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = round(precision_score(y_test, pred, average='micro'), ndigits=3)\n",
    "    recall = round(recall_score(y_test, pred, average='micro'), ndigits=3)\n",
    "    f1 = round(f1_score(y_test, pred, average='micro'), ndigits=3)\n",
    "    print('정확도:{0:,f},정밀도:{1:f},\\\n",
    "    재현율:{2:f},f1:{3:f}'.format(accuracy,precision,recall,f1),'\\n')\n",
    "# 모델 평가 지표 함수\n",
    "pred_proba = lgbm_wrapper.predict_proba(X_test)[:,1]\n",
    "get_clf_eval(y_test,preds,pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.8438818565400844\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame()\n",
    "list=os.listdir('./To/df_total_2019/')\n",
    "for list in list:\n",
    "    df1= pd.read_csv('./To/df_total_2019/{}'.format(list))\n",
    "    df=pd.concat([df,df1])\n",
    "df[['e4acc_x_mean','e4acc_y_mean','e4acc_z_mean']] = df[['e4acc_x_mean','e4acc_y_mean','e4acc_z_mean']].fillna(df[['macc_x_mean','macc_y_mean','macc_z_mean']])\n",
    "\n",
    "df = df.dropna(subset=['macc_x_mean', 'mgps_lat_std', 'e4acc_x_mean', 'temp_mean', 'bvp_std', 'hr_std'], axis=0)\n",
    "df = df[(df['action']!='sleep')&(df['action']!='recreation_etc')&(df['action']!='meal')&(df['action']!='hobby')]\n",
    "X = df.drop(['ts', 'action', 'actionOption', 'actionSub', 'actionSubOption', 'condition', 'conditionSub1Option', 'conditionSub2Option', 'place', 'emotionPositive', 'emotionTension', 'activity'], axis=1)\n",
    "y = df['action']\n",
    "\n",
    "\n",
    "\n",
    "## sleep은 추가적인 자료에 있고, 측정이 어렵기에 제거, recreation etc는 행위의 종류가 다양하여 제거 , 식사도 측정이 불가하다고 판단\n",
    "## 취미또한 한 테마안에 여러 활동이 포함되어 제거\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "\n",
    "## 수민님이 주신 scaler\n",
    "for col in X_train.columns:\n",
    "    scal = RobustScaler()\n",
    "    X_train[col] = scal.fit_transform(np.array(X_train[col]).reshape(-1, 1))\n",
    "    X_test[col] = scal.transform(np.array(X_test[col]).reshape(-1, 1))\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 400)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"정확도 : {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhm21\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\Users\\jhm21\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.41061\n",
      "[2]\tvalid_0's multi_logloss: 1.25579\n",
      "[3]\tvalid_0's multi_logloss: 1.1418\n",
      "[4]\tvalid_0's multi_logloss: 1.05554\n",
      "[5]\tvalid_0's multi_logloss: 0.98353\n",
      "[6]\tvalid_0's multi_logloss: 0.922603\n",
      "[7]\tvalid_0's multi_logloss: 0.870346\n",
      "[8]\tvalid_0's multi_logloss: 0.818289\n",
      "[9]\tvalid_0's multi_logloss: 0.773852\n",
      "[10]\tvalid_0's multi_logloss: 0.74068\n",
      "[11]\tvalid_0's multi_logloss: 0.712551\n",
      "[12]\tvalid_0's multi_logloss: 0.679153\n",
      "[13]\tvalid_0's multi_logloss: 0.658189\n",
      "[14]\tvalid_0's multi_logloss: 0.638774\n",
      "[15]\tvalid_0's multi_logloss: 0.622474\n",
      "[16]\tvalid_0's multi_logloss: 0.605809\n",
      "[17]\tvalid_0's multi_logloss: 0.589948\n",
      "[18]\tvalid_0's multi_logloss: 0.580141\n",
      "[19]\tvalid_0's multi_logloss: 0.567997\n",
      "[20]\tvalid_0's multi_logloss: 0.557791\n",
      "[21]\tvalid_0's multi_logloss: 0.552671\n",
      "[22]\tvalid_0's multi_logloss: 0.548785\n",
      "[23]\tvalid_0's multi_logloss: 0.542141\n",
      "[24]\tvalid_0's multi_logloss: 0.539731\n",
      "[25]\tvalid_0's multi_logloss: 0.536055\n",
      "[26]\tvalid_0's multi_logloss: 0.529819\n",
      "[27]\tvalid_0's multi_logloss: 0.525036\n",
      "[28]\tvalid_0's multi_logloss: 0.52301\n",
      "[29]\tvalid_0's multi_logloss: 0.52077\n",
      "[30]\tvalid_0's multi_logloss: 0.519465\n",
      "[31]\tvalid_0's multi_logloss: 0.51922\n",
      "[32]\tvalid_0's multi_logloss: 0.522167\n",
      "[33]\tvalid_0's multi_logloss: 0.519504\n",
      "[34]\tvalid_0's multi_logloss: 0.521092\n",
      "[35]\tvalid_0's multi_logloss: 0.522134\n",
      "[36]\tvalid_0's multi_logloss: 0.521217\n",
      "[37]\tvalid_0's multi_logloss: 0.520899\n",
      "[38]\tvalid_0's multi_logloss: 0.522247\n",
      "[39]\tvalid_0's multi_logloss: 0.525871\n",
      "[40]\tvalid_0's multi_logloss: 0.52941\n",
      "[41]\tvalid_0's multi_logloss: 0.533082\n",
      "[42]\tvalid_0's multi_logloss: 0.539347\n",
      "[43]\tvalid_0's multi_logloss: 0.541733\n",
      "[44]\tvalid_0's multi_logloss: 0.543461\n",
      "[45]\tvalid_0's multi_logloss: 0.54752\n",
      "[46]\tvalid_0's multi_logloss: 0.552264\n",
      "[47]\tvalid_0's multi_logloss: 0.552614\n",
      "[48]\tvalid_0's multi_logloss: 0.556058\n",
      "[49]\tvalid_0's multi_logloss: 0.561128\n",
      "[50]\tvalid_0's multi_logloss: 0.565946\n",
      "[51]\tvalid_0's multi_logloss: 0.567461\n",
      "[52]\tvalid_0's multi_logloss: 0.568008\n",
      "[53]\tvalid_0's multi_logloss: 0.575384\n",
      "[54]\tvalid_0's multi_logloss: 0.580183\n",
      "[55]\tvalid_0's multi_logloss: 0.584819\n",
      "[56]\tvalid_0's multi_logloss: 0.588668\n",
      "[57]\tvalid_0's multi_logloss: 0.590444\n",
      "[58]\tvalid_0's multi_logloss: 0.595877\n",
      "[59]\tvalid_0's multi_logloss: 0.598985\n",
      "[60]\tvalid_0's multi_logloss: 0.603447\n",
      "[61]\tvalid_0's multi_logloss: 0.606123\n",
      "[62]\tvalid_0's multi_logloss: 0.608301\n",
      "[63]\tvalid_0's multi_logloss: 0.612269\n",
      "[64]\tvalid_0's multi_logloss: 0.616281\n",
      "[65]\tvalid_0's multi_logloss: 0.61837\n",
      "[66]\tvalid_0's multi_logloss: 0.620627\n",
      "[67]\tvalid_0's multi_logloss: 0.623958\n",
      "[68]\tvalid_0's multi_logloss: 0.626531\n",
      "[69]\tvalid_0's multi_logloss: 0.630231\n",
      "[70]\tvalid_0's multi_logloss: 0.633631\n",
      "[71]\tvalid_0's multi_logloss: 0.638945\n",
      "[72]\tvalid_0's multi_logloss: 0.644706\n",
      "[73]\tvalid_0's multi_logloss: 0.650873\n",
      "[74]\tvalid_0's multi_logloss: 0.655327\n",
      "[75]\tvalid_0's multi_logloss: 0.65879\n",
      "[76]\tvalid_0's multi_logloss: 0.662205\n",
      "[77]\tvalid_0's multi_logloss: 0.668333\n",
      "[78]\tvalid_0's multi_logloss: 0.669212\n",
      "[79]\tvalid_0's multi_logloss: 0.673099\n",
      "[80]\tvalid_0's multi_logloss: 0.676681\n",
      "[81]\tvalid_0's multi_logloss: 0.674554\n",
      "[82]\tvalid_0's multi_logloss: 0.680161\n",
      "[83]\tvalid_0's multi_logloss: 0.680886\n",
      "[84]\tvalid_0's multi_logloss: 0.686775\n",
      "[85]\tvalid_0's multi_logloss: 0.686549\n",
      "[86]\tvalid_0's multi_logloss: 0.689019\n",
      "[87]\tvalid_0's multi_logloss: 0.692244\n",
      "[88]\tvalid_0's multi_logloss: 0.693966\n",
      "[89]\tvalid_0's multi_logloss: 0.696854\n",
      "[90]\tvalid_0's multi_logloss: 0.697634\n",
      "[91]\tvalid_0's multi_logloss: 0.701814\n",
      "[92]\tvalid_0's multi_logloss: 0.702372\n",
      "[93]\tvalid_0's multi_logloss: 0.702465\n",
      "[94]\tvalid_0's multi_logloss: 0.703793\n",
      "[95]\tvalid_0's multi_logloss: 0.706505\n",
      "[96]\tvalid_0's multi_logloss: 0.707796\n",
      "[97]\tvalid_0's multi_logloss: 0.706678\n",
      "[98]\tvalid_0's multi_logloss: 0.70838\n",
      "[99]\tvalid_0's multi_logloss: 0.708897\n",
      "[100]\tvalid_0's multi_logloss: 0.707576\n",
      "정확도:0.873418,정밀도:0.873000,    재현율:0.873000,f1:0.873000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm_wrapper = LGBMClassifier(n_estimators=100)\n",
    "evals=[(X_test,y_test)]\n",
    "lgbm_wrapper.fit(X_train, y_train, early_stopping_rounds=1000, eval_metric='logloss', eval_set=evals, verbose=True)\n",
    "preds = lgbm_wrapper.predict(X_test)\n",
    "## n_ estimator 가 200을 넘어가면 오히려 loss 가 증가하는 경향을 보여서 100으로 설정\n",
    "def get_clf_eval(y_test,pred = None,pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = round(precision_score(y_test, pred, average='micro'), ndigits=3)\n",
    "    recall = round(recall_score(y_test, pred, average='micro'), ndigits=3)\n",
    "    f1 = round(f1_score(y_test, pred, average='micro'), ndigits=3)\n",
    "    print('정확도:{0:,f},정밀도:{1:f},\\\n",
    "    재현율:{2:f},f1:{3:f}'.format(accuracy,precision,recall,f1),'\\n')\n",
    "# 모델 평가 지표 함수\n",
    "pred_proba = lgbm_wrapper.predict_proba(X_test)[:,1]\n",
    "get_clf_eval(y_test,preds,pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "list=os.listdir('./total/')\n",
    "for list in list:\n",
    "    df1= pd.read_csv('./total/{}'.format(list))\n",
    "    df1=df1[['action','macc_x_mean','e4acc_x_mean','macc_y_mean','e4acc_y_mean','macc_z_mean','e4acc_z_mean']]\n",
    "    df=pd.concat([df,df1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.7447273162413618\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['macc_x_mean', 'e4acc_x_mean'], axis=0)\n",
    "df = df[(df['action']!='sleep')&(df['action']!='recreation_etc')&(df['action']!='meal')&(df['action']!='hobby')]\n",
    "X = df.drop(['action'], axis=1)\n",
    "y = df['action']\n",
    "\n",
    "\n",
    "## sleep은 추가적인 자료에 있고, 측정이 어렵기에 제거, recreation etc는 행위의 종류가 다양하여 제거 , 식사도 측정이 불가하다고 판단\n",
    "## 취미또한 한 테마안에 여러 활동이 포함되어 제거\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "\n",
    "## 수민님이 주신 scaler\n",
    "for col in X_train.columns:\n",
    "    scal = RobustScaler()\n",
    "    X_train[col] = scal.fit_transform(np.array(X_train[col]).reshape(-1, 1))\n",
    "    X_test[col] = scal.transform(np.array(X_test[col]).reshape(-1, 1))\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 400)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"정확도 : {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhm21\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\Users\\jhm21\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.53571\n",
      "[2]\tvalid_0's multi_logloss: 1.45628\n",
      "[3]\tvalid_0's multi_logloss: 1.40041\n",
      "[4]\tvalid_0's multi_logloss: 1.35754\n",
      "[5]\tvalid_0's multi_logloss: 1.32149\n",
      "[6]\tvalid_0's multi_logloss: 1.29297\n",
      "[7]\tvalid_0's multi_logloss: 1.26821\n",
      "[8]\tvalid_0's multi_logloss: 1.24621\n",
      "[9]\tvalid_0's multi_logloss: 1.2272\n",
      "[10]\tvalid_0's multi_logloss: 1.21048\n",
      "[11]\tvalid_0's multi_logloss: 1.19671\n",
      "[12]\tvalid_0's multi_logloss: 1.18306\n",
      "[13]\tvalid_0's multi_logloss: 1.17107\n",
      "[14]\tvalid_0's multi_logloss: 1.16142\n",
      "[15]\tvalid_0's multi_logloss: 1.15043\n",
      "[16]\tvalid_0's multi_logloss: 1.14083\n",
      "[17]\tvalid_0's multi_logloss: 1.13232\n",
      "[18]\tvalid_0's multi_logloss: 1.12596\n",
      "[19]\tvalid_0's multi_logloss: 1.11842\n",
      "[20]\tvalid_0's multi_logloss: 1.11084\n",
      "[21]\tvalid_0's multi_logloss: 1.10444\n",
      "[22]\tvalid_0's multi_logloss: 1.09848\n",
      "[23]\tvalid_0's multi_logloss: 1.09321\n",
      "[24]\tvalid_0's multi_logloss: 1.08742\n",
      "[25]\tvalid_0's multi_logloss: 1.08226\n",
      "[26]\tvalid_0's multi_logloss: 1.07768\n",
      "[27]\tvalid_0's multi_logloss: 1.07305\n",
      "[28]\tvalid_0's multi_logloss: 1.06855\n",
      "[29]\tvalid_0's multi_logloss: 1.06358\n",
      "[30]\tvalid_0's multi_logloss: 1.06024\n",
      "[31]\tvalid_0's multi_logloss: 1.05649\n",
      "[32]\tvalid_0's multi_logloss: 1.05286\n",
      "[33]\tvalid_0's multi_logloss: 1.04942\n",
      "[34]\tvalid_0's multi_logloss: 1.04563\n",
      "[35]\tvalid_0's multi_logloss: 1.0419\n",
      "[36]\tvalid_0's multi_logloss: 1.03909\n",
      "[37]\tvalid_0's multi_logloss: 1.03635\n",
      "[38]\tvalid_0's multi_logloss: 1.03345\n",
      "[39]\tvalid_0's multi_logloss: 1.03071\n",
      "[40]\tvalid_0's multi_logloss: 1.02837\n",
      "[41]\tvalid_0's multi_logloss: 1.02593\n",
      "[42]\tvalid_0's multi_logloss: 1.02382\n",
      "[43]\tvalid_0's multi_logloss: 1.02138\n",
      "[44]\tvalid_0's multi_logloss: 1.01958\n",
      "[45]\tvalid_0's multi_logloss: 1.01714\n",
      "[46]\tvalid_0's multi_logloss: 1.0152\n",
      "[47]\tvalid_0's multi_logloss: 1.01275\n",
      "[48]\tvalid_0's multi_logloss: 1.01115\n",
      "[49]\tvalid_0's multi_logloss: 1.00923\n",
      "[50]\tvalid_0's multi_logloss: 1.00774\n",
      "[51]\tvalid_0's multi_logloss: 1.00631\n",
      "[52]\tvalid_0's multi_logloss: 1.00413\n",
      "[53]\tvalid_0's multi_logloss: 1.00246\n",
      "[54]\tvalid_0's multi_logloss: 1.00077\n",
      "[55]\tvalid_0's multi_logloss: 0.999286\n",
      "[56]\tvalid_0's multi_logloss: 0.997085\n",
      "[57]\tvalid_0's multi_logloss: 0.995486\n",
      "[58]\tvalid_0's multi_logloss: 0.994115\n",
      "[59]\tvalid_0's multi_logloss: 0.992613\n",
      "[60]\tvalid_0's multi_logloss: 0.991155\n",
      "[61]\tvalid_0's multi_logloss: 0.988818\n",
      "[62]\tvalid_0's multi_logloss: 0.986702\n",
      "[63]\tvalid_0's multi_logloss: 0.984712\n",
      "[64]\tvalid_0's multi_logloss: 0.983198\n",
      "[65]\tvalid_0's multi_logloss: 0.981357\n",
      "[66]\tvalid_0's multi_logloss: 0.979531\n",
      "[67]\tvalid_0's multi_logloss: 0.978009\n",
      "[68]\tvalid_0's multi_logloss: 0.976413\n",
      "[69]\tvalid_0's multi_logloss: 0.974726\n",
      "[70]\tvalid_0's multi_logloss: 0.972714\n",
      "[71]\tvalid_0's multi_logloss: 0.970861\n",
      "[72]\tvalid_0's multi_logloss: 0.969695\n",
      "[73]\tvalid_0's multi_logloss: 0.968212\n",
      "[74]\tvalid_0's multi_logloss: 0.967005\n",
      "[75]\tvalid_0's multi_logloss: 0.965919\n",
      "[76]\tvalid_0's multi_logloss: 0.964676\n",
      "[77]\tvalid_0's multi_logloss: 0.963323\n",
      "[78]\tvalid_0's multi_logloss: 0.961949\n",
      "[79]\tvalid_0's multi_logloss: 0.960493\n",
      "[80]\tvalid_0's multi_logloss: 0.959322\n",
      "[81]\tvalid_0's multi_logloss: 0.958355\n",
      "[82]\tvalid_0's multi_logloss: 0.957538\n",
      "[83]\tvalid_0's multi_logloss: 0.955984\n",
      "[84]\tvalid_0's multi_logloss: 0.954333\n",
      "[85]\tvalid_0's multi_logloss: 0.952734\n",
      "[86]\tvalid_0's multi_logloss: 0.95089\n",
      "[87]\tvalid_0's multi_logloss: 0.949862\n",
      "[88]\tvalid_0's multi_logloss: 0.948314\n",
      "[89]\tvalid_0's multi_logloss: 0.947332\n",
      "[90]\tvalid_0's multi_logloss: 0.946417\n",
      "[91]\tvalid_0's multi_logloss: 0.945374\n",
      "[92]\tvalid_0's multi_logloss: 0.944496\n",
      "[93]\tvalid_0's multi_logloss: 0.943189\n",
      "[94]\tvalid_0's multi_logloss: 0.942386\n",
      "[95]\tvalid_0's multi_logloss: 0.941326\n",
      "[96]\tvalid_0's multi_logloss: 0.94055\n",
      "[97]\tvalid_0's multi_logloss: 0.93982\n",
      "[98]\tvalid_0's multi_logloss: 0.93857\n",
      "[99]\tvalid_0's multi_logloss: 0.937393\n",
      "[100]\tvalid_0's multi_logloss: 0.9362\n",
      "[101]\tvalid_0's multi_logloss: 0.934858\n",
      "[102]\tvalid_0's multi_logloss: 0.933888\n",
      "[103]\tvalid_0's multi_logloss: 0.932764\n",
      "[104]\tvalid_0's multi_logloss: 0.931403\n",
      "[105]\tvalid_0's multi_logloss: 0.930278\n",
      "[106]\tvalid_0's multi_logloss: 0.929482\n",
      "[107]\tvalid_0's multi_logloss: 0.928622\n",
      "[108]\tvalid_0's multi_logloss: 0.927793\n",
      "[109]\tvalid_0's multi_logloss: 0.927048\n",
      "[110]\tvalid_0's multi_logloss: 0.925995\n",
      "[111]\tvalid_0's multi_logloss: 0.925332\n",
      "[112]\tvalid_0's multi_logloss: 0.924778\n",
      "[113]\tvalid_0's multi_logloss: 0.92414\n",
      "[114]\tvalid_0's multi_logloss: 0.922784\n",
      "[115]\tvalid_0's multi_logloss: 0.922036\n",
      "[116]\tvalid_0's multi_logloss: 0.92139\n",
      "[117]\tvalid_0's multi_logloss: 0.920503\n",
      "[118]\tvalid_0's multi_logloss: 0.919878\n",
      "[119]\tvalid_0's multi_logloss: 0.918997\n",
      "[120]\tvalid_0's multi_logloss: 0.918319\n",
      "[121]\tvalid_0's multi_logloss: 0.917922\n",
      "[122]\tvalid_0's multi_logloss: 0.917285\n",
      "[123]\tvalid_0's multi_logloss: 0.916365\n",
      "[124]\tvalid_0's multi_logloss: 0.915823\n",
      "[125]\tvalid_0's multi_logloss: 0.9153\n",
      "[126]\tvalid_0's multi_logloss: 0.914224\n",
      "[127]\tvalid_0's multi_logloss: 0.913315\n",
      "[128]\tvalid_0's multi_logloss: 0.911973\n",
      "[129]\tvalid_0's multi_logloss: 0.911195\n",
      "[130]\tvalid_0's multi_logloss: 0.909972\n",
      "[131]\tvalid_0's multi_logloss: 0.908944\n",
      "[132]\tvalid_0's multi_logloss: 0.908099\n",
      "[133]\tvalid_0's multi_logloss: 0.906803\n",
      "[134]\tvalid_0's multi_logloss: 0.905916\n",
      "[135]\tvalid_0's multi_logloss: 0.905288\n",
      "[136]\tvalid_0's multi_logloss: 0.904564\n",
      "[137]\tvalid_0's multi_logloss: 0.903578\n",
      "[138]\tvalid_0's multi_logloss: 0.903138\n",
      "[139]\tvalid_0's multi_logloss: 0.902719\n",
      "[140]\tvalid_0's multi_logloss: 0.901889\n",
      "[141]\tvalid_0's multi_logloss: 0.901173\n",
      "[142]\tvalid_0's multi_logloss: 0.900251\n",
      "[143]\tvalid_0's multi_logloss: 0.899553\n",
      "[144]\tvalid_0's multi_logloss: 0.898804\n",
      "[145]\tvalid_0's multi_logloss: 0.897982\n",
      "[146]\tvalid_0's multi_logloss: 0.896812\n",
      "[147]\tvalid_0's multi_logloss: 0.896022\n",
      "[148]\tvalid_0's multi_logloss: 0.89553\n",
      "[149]\tvalid_0's multi_logloss: 0.895135\n",
      "[150]\tvalid_0's multi_logloss: 0.89446\n",
      "[151]\tvalid_0's multi_logloss: 0.893611\n",
      "[152]\tvalid_0's multi_logloss: 0.892569\n",
      "[153]\tvalid_0's multi_logloss: 0.892091\n",
      "[154]\tvalid_0's multi_logloss: 0.891506\n",
      "[155]\tvalid_0's multi_logloss: 0.891002\n",
      "[156]\tvalid_0's multi_logloss: 0.890167\n",
      "[157]\tvalid_0's multi_logloss: 0.889885\n",
      "[158]\tvalid_0's multi_logloss: 0.889257\n",
      "[159]\tvalid_0's multi_logloss: 0.888943\n",
      "[160]\tvalid_0's multi_logloss: 0.888453\n",
      "[161]\tvalid_0's multi_logloss: 0.888175\n",
      "[162]\tvalid_0's multi_logloss: 0.88746\n",
      "[163]\tvalid_0's multi_logloss: 0.886838\n",
      "[164]\tvalid_0's multi_logloss: 0.886279\n",
      "[165]\tvalid_0's multi_logloss: 0.885785\n",
      "[166]\tvalid_0's multi_logloss: 0.885414\n",
      "[167]\tvalid_0's multi_logloss: 0.884933\n",
      "[168]\tvalid_0's multi_logloss: 0.884395\n",
      "[169]\tvalid_0's multi_logloss: 0.883892\n",
      "[170]\tvalid_0's multi_logloss: 0.883267\n",
      "[171]\tvalid_0's multi_logloss: 0.882885\n",
      "[172]\tvalid_0's multi_logloss: 0.882266\n",
      "[173]\tvalid_0's multi_logloss: 0.881437\n",
      "[174]\tvalid_0's multi_logloss: 0.880733\n",
      "[175]\tvalid_0's multi_logloss: 0.879814\n",
      "[176]\tvalid_0's multi_logloss: 0.879459\n",
      "[177]\tvalid_0's multi_logloss: 0.879142\n",
      "[178]\tvalid_0's multi_logloss: 0.878637\n",
      "[179]\tvalid_0's multi_logloss: 0.877717\n",
      "[180]\tvalid_0's multi_logloss: 0.877226\n",
      "[181]\tvalid_0's multi_logloss: 0.876861\n",
      "[182]\tvalid_0's multi_logloss: 0.876537\n",
      "[183]\tvalid_0's multi_logloss: 0.876214\n",
      "[184]\tvalid_0's multi_logloss: 0.875481\n",
      "[185]\tvalid_0's multi_logloss: 0.875305\n",
      "[186]\tvalid_0's multi_logloss: 0.874979\n",
      "[187]\tvalid_0's multi_logloss: 0.874648\n",
      "[188]\tvalid_0's multi_logloss: 0.874309\n",
      "[189]\tvalid_0's multi_logloss: 0.873272\n",
      "[190]\tvalid_0's multi_logloss: 0.87264\n",
      "[191]\tvalid_0's multi_logloss: 0.872311\n",
      "[192]\tvalid_0's multi_logloss: 0.871692\n",
      "[193]\tvalid_0's multi_logloss: 0.870988\n",
      "[194]\tvalid_0's multi_logloss: 0.870106\n",
      "[195]\tvalid_0's multi_logloss: 0.869653\n",
      "[196]\tvalid_0's multi_logloss: 0.86929\n",
      "[197]\tvalid_0's multi_logloss: 0.868967\n",
      "[198]\tvalid_0's multi_logloss: 0.868659\n",
      "[199]\tvalid_0's multi_logloss: 0.868245\n",
      "[200]\tvalid_0's multi_logloss: 0.867931\n",
      "[201]\tvalid_0's multi_logloss: 0.867658\n",
      "[202]\tvalid_0's multi_logloss: 0.86751\n",
      "[203]\tvalid_0's multi_logloss: 0.867077\n",
      "[204]\tvalid_0's multi_logloss: 0.866547\n",
      "[205]\tvalid_0's multi_logloss: 0.866101\n",
      "[206]\tvalid_0's multi_logloss: 0.865842\n",
      "[207]\tvalid_0's multi_logloss: 0.865645\n",
      "[208]\tvalid_0's multi_logloss: 0.865395\n",
      "[209]\tvalid_0's multi_logloss: 0.864899\n",
      "[210]\tvalid_0's multi_logloss: 0.864485\n",
      "[211]\tvalid_0's multi_logloss: 0.864137\n",
      "[212]\tvalid_0's multi_logloss: 0.863973\n",
      "[213]\tvalid_0's multi_logloss: 0.863666\n",
      "[214]\tvalid_0's multi_logloss: 0.863057\n",
      "[215]\tvalid_0's multi_logloss: 0.86258\n",
      "[216]\tvalid_0's multi_logloss: 0.862027\n",
      "[217]\tvalid_0's multi_logloss: 0.861582\n",
      "[218]\tvalid_0's multi_logloss: 0.861386\n",
      "[219]\tvalid_0's multi_logloss: 0.861167\n",
      "[220]\tvalid_0's multi_logloss: 0.860729\n",
      "[221]\tvalid_0's multi_logloss: 0.860334\n",
      "[222]\tvalid_0's multi_logloss: 0.859953\n",
      "[223]\tvalid_0's multi_logloss: 0.85975\n",
      "[224]\tvalid_0's multi_logloss: 0.859438\n",
      "[225]\tvalid_0's multi_logloss: 0.859073\n",
      "[226]\tvalid_0's multi_logloss: 0.85867\n",
      "[227]\tvalid_0's multi_logloss: 0.858511\n",
      "[228]\tvalid_0's multi_logloss: 0.858136\n",
      "[229]\tvalid_0's multi_logloss: 0.857905\n",
      "[230]\tvalid_0's multi_logloss: 0.857756\n",
      "[231]\tvalid_0's multi_logloss: 0.857058\n",
      "[232]\tvalid_0's multi_logloss: 0.856591\n",
      "[233]\tvalid_0's multi_logloss: 0.856235\n",
      "[234]\tvalid_0's multi_logloss: 0.855696\n",
      "[235]\tvalid_0's multi_logloss: 0.855199\n",
      "[236]\tvalid_0's multi_logloss: 0.854874\n",
      "[237]\tvalid_0's multi_logloss: 0.854619\n",
      "[238]\tvalid_0's multi_logloss: 0.854212\n",
      "[239]\tvalid_0's multi_logloss: 0.853649\n",
      "[240]\tvalid_0's multi_logloss: 0.853489\n",
      "[241]\tvalid_0's multi_logloss: 0.852971\n",
      "[242]\tvalid_0's multi_logloss: 0.852592\n",
      "[243]\tvalid_0's multi_logloss: 0.852268\n",
      "[244]\tvalid_0's multi_logloss: 0.851801\n",
      "[245]\tvalid_0's multi_logloss: 0.851307\n",
      "[246]\tvalid_0's multi_logloss: 0.85097\n",
      "[247]\tvalid_0's multi_logloss: 0.850736\n",
      "[248]\tvalid_0's multi_logloss: 0.850639\n",
      "[249]\tvalid_0's multi_logloss: 0.850461\n",
      "[250]\tvalid_0's multi_logloss: 0.850251\n",
      "[251]\tvalid_0's multi_logloss: 0.850013\n",
      "[252]\tvalid_0's multi_logloss: 0.849777\n",
      "[253]\tvalid_0's multi_logloss: 0.849571\n",
      "[254]\tvalid_0's multi_logloss: 0.848947\n",
      "[255]\tvalid_0's multi_logloss: 0.848277\n",
      "[256]\tvalid_0's multi_logloss: 0.847729\n",
      "[257]\tvalid_0's multi_logloss: 0.847545\n",
      "[258]\tvalid_0's multi_logloss: 0.847062\n",
      "[259]\tvalid_0's multi_logloss: 0.846823\n",
      "[260]\tvalid_0's multi_logloss: 0.846418\n",
      "[261]\tvalid_0's multi_logloss: 0.846307\n",
      "[262]\tvalid_0's multi_logloss: 0.845928\n",
      "[263]\tvalid_0's multi_logloss: 0.845751\n",
      "[264]\tvalid_0's multi_logloss: 0.84567\n",
      "[265]\tvalid_0's multi_logloss: 0.845436\n",
      "[266]\tvalid_0's multi_logloss: 0.845291\n",
      "[267]\tvalid_0's multi_logloss: 0.845034\n",
      "[268]\tvalid_0's multi_logloss: 0.844401\n",
      "[269]\tvalid_0's multi_logloss: 0.844114\n",
      "[270]\tvalid_0's multi_logloss: 0.844023\n",
      "[271]\tvalid_0's multi_logloss: 0.843893\n",
      "[272]\tvalid_0's multi_logloss: 0.843637\n",
      "[273]\tvalid_0's multi_logloss: 0.843337\n",
      "[274]\tvalid_0's multi_logloss: 0.843025\n",
      "[275]\tvalid_0's multi_logloss: 0.842733\n",
      "[276]\tvalid_0's multi_logloss: 0.842491\n",
      "[277]\tvalid_0's multi_logloss: 0.84211\n",
      "[278]\tvalid_0's multi_logloss: 0.841708\n",
      "[279]\tvalid_0's multi_logloss: 0.841402\n",
      "[280]\tvalid_0's multi_logloss: 0.84125\n",
      "[281]\tvalid_0's multi_logloss: 0.841195\n",
      "[282]\tvalid_0's multi_logloss: 0.840837\n",
      "[283]\tvalid_0's multi_logloss: 0.840384\n",
      "[284]\tvalid_0's multi_logloss: 0.840218\n",
      "[285]\tvalid_0's multi_logloss: 0.83986\n",
      "[286]\tvalid_0's multi_logloss: 0.839598\n",
      "[287]\tvalid_0's multi_logloss: 0.839377\n",
      "[288]\tvalid_0's multi_logloss: 0.839098\n",
      "[289]\tvalid_0's multi_logloss: 0.838968\n",
      "[290]\tvalid_0's multi_logloss: 0.838781\n",
      "[291]\tvalid_0's multi_logloss: 0.838584\n",
      "[292]\tvalid_0's multi_logloss: 0.838333\n",
      "[293]\tvalid_0's multi_logloss: 0.838145\n",
      "[294]\tvalid_0's multi_logloss: 0.837948\n",
      "[295]\tvalid_0's multi_logloss: 0.83769\n",
      "[296]\tvalid_0's multi_logloss: 0.837379\n",
      "[297]\tvalid_0's multi_logloss: 0.837043\n",
      "[298]\tvalid_0's multi_logloss: 0.836721\n",
      "[299]\tvalid_0's multi_logloss: 0.836573\n",
      "[300]\tvalid_0's multi_logloss: 0.836375\n",
      "[301]\tvalid_0's multi_logloss: 0.836186\n",
      "[302]\tvalid_0's multi_logloss: 0.835869\n",
      "[303]\tvalid_0's multi_logloss: 0.835719\n",
      "[304]\tvalid_0's multi_logloss: 0.835535\n",
      "[305]\tvalid_0's multi_logloss: 0.835273\n",
      "[306]\tvalid_0's multi_logloss: 0.83511\n",
      "[307]\tvalid_0's multi_logloss: 0.834869\n",
      "[308]\tvalid_0's multi_logloss: 0.834682\n",
      "[309]\tvalid_0's multi_logloss: 0.834593\n",
      "[310]\tvalid_0's multi_logloss: 0.834398\n",
      "[311]\tvalid_0's multi_logloss: 0.834153\n",
      "[312]\tvalid_0's multi_logloss: 0.833686\n",
      "[313]\tvalid_0's multi_logloss: 0.833585\n",
      "[314]\tvalid_0's multi_logloss: 0.833361\n",
      "[315]\tvalid_0's multi_logloss: 0.833251\n",
      "[316]\tvalid_0's multi_logloss: 0.833092\n",
      "[317]\tvalid_0's multi_logloss: 0.833032\n",
      "[318]\tvalid_0's multi_logloss: 0.832796\n",
      "[319]\tvalid_0's multi_logloss: 0.832647\n",
      "[320]\tvalid_0's multi_logloss: 0.832414\n",
      "[321]\tvalid_0's multi_logloss: 0.832195\n",
      "[322]\tvalid_0's multi_logloss: 0.83201\n",
      "[323]\tvalid_0's multi_logloss: 0.831965\n",
      "[324]\tvalid_0's multi_logloss: 0.831746\n",
      "[325]\tvalid_0's multi_logloss: 0.831458\n",
      "[326]\tvalid_0's multi_logloss: 0.831113\n",
      "[327]\tvalid_0's multi_logloss: 0.83095\n",
      "[328]\tvalid_0's multi_logloss: 0.830456\n",
      "[329]\tvalid_0's multi_logloss: 0.830164\n",
      "[330]\tvalid_0's multi_logloss: 0.829978\n",
      "[331]\tvalid_0's multi_logloss: 0.829861\n",
      "[332]\tvalid_0's multi_logloss: 0.829769\n",
      "[333]\tvalid_0's multi_logloss: 0.82963\n",
      "[334]\tvalid_0's multi_logloss: 0.829548\n",
      "[335]\tvalid_0's multi_logloss: 0.829451\n",
      "[336]\tvalid_0's multi_logloss: 0.829418\n",
      "[337]\tvalid_0's multi_logloss: 0.829245\n",
      "[338]\tvalid_0's multi_logloss: 0.82917\n",
      "[339]\tvalid_0's multi_logloss: 0.829031\n",
      "[340]\tvalid_0's multi_logloss: 0.828923\n",
      "[341]\tvalid_0's multi_logloss: 0.828774\n",
      "[342]\tvalid_0's multi_logloss: 0.828598\n",
      "[343]\tvalid_0's multi_logloss: 0.828533\n",
      "[344]\tvalid_0's multi_logloss: 0.82834\n",
      "[345]\tvalid_0's multi_logloss: 0.828239\n",
      "[346]\tvalid_0's multi_logloss: 0.82824\n",
      "[347]\tvalid_0's multi_logloss: 0.828106\n",
      "[348]\tvalid_0's multi_logloss: 0.82801\n",
      "[349]\tvalid_0's multi_logloss: 0.82792\n",
      "[350]\tvalid_0's multi_logloss: 0.827946\n",
      "[351]\tvalid_0's multi_logloss: 0.827804\n",
      "[352]\tvalid_0's multi_logloss: 0.827794\n",
      "[353]\tvalid_0's multi_logloss: 0.827579\n",
      "[354]\tvalid_0's multi_logloss: 0.827377\n",
      "[355]\tvalid_0's multi_logloss: 0.827326\n",
      "[356]\tvalid_0's multi_logloss: 0.827024\n",
      "[357]\tvalid_0's multi_logloss: 0.826843\n",
      "[358]\tvalid_0's multi_logloss: 0.826752\n",
      "[359]\tvalid_0's multi_logloss: 0.826551\n",
      "[360]\tvalid_0's multi_logloss: 0.826414\n",
      "[361]\tvalid_0's multi_logloss: 0.826392\n",
      "[362]\tvalid_0's multi_logloss: 0.826233\n",
      "[363]\tvalid_0's multi_logloss: 0.826053\n",
      "[364]\tvalid_0's multi_logloss: 0.825851\n",
      "[365]\tvalid_0's multi_logloss: 0.825774\n",
      "[366]\tvalid_0's multi_logloss: 0.825523\n",
      "[367]\tvalid_0's multi_logloss: 0.825383\n",
      "[368]\tvalid_0's multi_logloss: 0.82538\n",
      "[369]\tvalid_0's multi_logloss: 0.825399\n",
      "[370]\tvalid_0's multi_logloss: 0.82523\n",
      "[371]\tvalid_0's multi_logloss: 0.825032\n",
      "[372]\tvalid_0's multi_logloss: 0.824808\n",
      "[373]\tvalid_0's multi_logloss: 0.824629\n",
      "[374]\tvalid_0's multi_logloss: 0.824632\n",
      "[375]\tvalid_0's multi_logloss: 0.824466\n",
      "[376]\tvalid_0's multi_logloss: 0.824339\n",
      "[377]\tvalid_0's multi_logloss: 0.82422\n",
      "[378]\tvalid_0's multi_logloss: 0.82409\n",
      "[379]\tvalid_0's multi_logloss: 0.824042\n",
      "[380]\tvalid_0's multi_logloss: 0.823777\n",
      "[381]\tvalid_0's multi_logloss: 0.823599\n",
      "[382]\tvalid_0's multi_logloss: 0.823517\n",
      "[383]\tvalid_0's multi_logloss: 0.823467\n",
      "[384]\tvalid_0's multi_logloss: 0.823348\n",
      "[385]\tvalid_0's multi_logloss: 0.823225\n",
      "[386]\tvalid_0's multi_logloss: 0.823156\n",
      "[387]\tvalid_0's multi_logloss: 0.822819\n",
      "[388]\tvalid_0's multi_logloss: 0.822727\n",
      "[389]\tvalid_0's multi_logloss: 0.822694\n",
      "[390]\tvalid_0's multi_logloss: 0.822604\n",
      "[391]\tvalid_0's multi_logloss: 0.822535\n",
      "[392]\tvalid_0's multi_logloss: 0.822423\n",
      "[393]\tvalid_0's multi_logloss: 0.822264\n",
      "[394]\tvalid_0's multi_logloss: 0.822123\n",
      "[395]\tvalid_0's multi_logloss: 0.821844\n",
      "[396]\tvalid_0's multi_logloss: 0.821615\n",
      "[397]\tvalid_0's multi_logloss: 0.821536\n",
      "[398]\tvalid_0's multi_logloss: 0.821533\n",
      "[399]\tvalid_0's multi_logloss: 0.821281\n",
      "[400]\tvalid_0's multi_logloss: 0.821256\n",
      "[401]\tvalid_0's multi_logloss: 0.821064\n",
      "[402]\tvalid_0's multi_logloss: 0.820944\n",
      "[403]\tvalid_0's multi_logloss: 0.820842\n",
      "[404]\tvalid_0's multi_logloss: 0.820679\n",
      "[405]\tvalid_0's multi_logloss: 0.820504\n",
      "[406]\tvalid_0's multi_logloss: 0.820357\n",
      "[407]\tvalid_0's multi_logloss: 0.820325\n",
      "[408]\tvalid_0's multi_logloss: 0.820229\n",
      "[409]\tvalid_0's multi_logloss: 0.820141\n",
      "[410]\tvalid_0's multi_logloss: 0.820049\n",
      "[411]\tvalid_0's multi_logloss: 0.819814\n",
      "[412]\tvalid_0's multi_logloss: 0.819761\n",
      "[413]\tvalid_0's multi_logloss: 0.819604\n",
      "[414]\tvalid_0's multi_logloss: 0.819527\n",
      "[415]\tvalid_0's multi_logloss: 0.819483\n",
      "[416]\tvalid_0's multi_logloss: 0.819467\n",
      "[417]\tvalid_0's multi_logloss: 0.819288\n",
      "[418]\tvalid_0's multi_logloss: 0.819217\n",
      "[419]\tvalid_0's multi_logloss: 0.819157\n",
      "[420]\tvalid_0's multi_logloss: 0.819156\n",
      "[421]\tvalid_0's multi_logloss: 0.819123\n",
      "[422]\tvalid_0's multi_logloss: 0.819121\n",
      "[423]\tvalid_0's multi_logloss: 0.819013\n",
      "[424]\tvalid_0's multi_logloss: 0.818958\n",
      "[425]\tvalid_0's multi_logloss: 0.818905\n",
      "[426]\tvalid_0's multi_logloss: 0.818922\n",
      "[427]\tvalid_0's multi_logloss: 0.818847\n",
      "[428]\tvalid_0's multi_logloss: 0.818841\n",
      "[429]\tvalid_0's multi_logloss: 0.818796\n",
      "[430]\tvalid_0's multi_logloss: 0.818619\n",
      "[431]\tvalid_0's multi_logloss: 0.8186\n",
      "[432]\tvalid_0's multi_logloss: 0.818505\n",
      "[433]\tvalid_0's multi_logloss: 0.818345\n",
      "[434]\tvalid_0's multi_logloss: 0.81826\n",
      "[435]\tvalid_0's multi_logloss: 0.818207\n",
      "[436]\tvalid_0's multi_logloss: 0.818057\n",
      "[437]\tvalid_0's multi_logloss: 0.818089\n",
      "[438]\tvalid_0's multi_logloss: 0.818061\n",
      "[439]\tvalid_0's multi_logloss: 0.818003\n",
      "[440]\tvalid_0's multi_logloss: 0.817986\n",
      "[441]\tvalid_0's multi_logloss: 0.817889\n",
      "[442]\tvalid_0's multi_logloss: 0.817799\n",
      "[443]\tvalid_0's multi_logloss: 0.817681\n",
      "[444]\tvalid_0's multi_logloss: 0.817606\n",
      "[445]\tvalid_0's multi_logloss: 0.817439\n",
      "[446]\tvalid_0's multi_logloss: 0.817281\n",
      "[447]\tvalid_0's multi_logloss: 0.817302\n",
      "[448]\tvalid_0's multi_logloss: 0.817213\n",
      "[449]\tvalid_0's multi_logloss: 0.81707\n",
      "[450]\tvalid_0's multi_logloss: 0.816887\n",
      "[451]\tvalid_0's multi_logloss: 0.816752\n",
      "[452]\tvalid_0's multi_logloss: 0.816628\n",
      "[453]\tvalid_0's multi_logloss: 0.816559\n",
      "[454]\tvalid_0's multi_logloss: 0.816513\n",
      "[455]\tvalid_0's multi_logloss: 0.816402\n",
      "[456]\tvalid_0's multi_logloss: 0.816431\n",
      "[457]\tvalid_0's multi_logloss: 0.816257\n",
      "[458]\tvalid_0's multi_logloss: 0.816184\n",
      "[459]\tvalid_0's multi_logloss: 0.816174\n",
      "[460]\tvalid_0's multi_logloss: 0.816105\n",
      "[461]\tvalid_0's multi_logloss: 0.816085\n",
      "[462]\tvalid_0's multi_logloss: 0.815964\n",
      "[463]\tvalid_0's multi_logloss: 0.815853\n",
      "[464]\tvalid_0's multi_logloss: 0.815839\n",
      "[465]\tvalid_0's multi_logloss: 0.815872\n",
      "[466]\tvalid_0's multi_logloss: 0.815817\n",
      "[467]\tvalid_0's multi_logloss: 0.815745\n",
      "[468]\tvalid_0's multi_logloss: 0.81568\n",
      "[469]\tvalid_0's multi_logloss: 0.815697\n",
      "[470]\tvalid_0's multi_logloss: 0.815577\n",
      "[471]\tvalid_0's multi_logloss: 0.815409\n",
      "[472]\tvalid_0's multi_logloss: 0.815385\n",
      "[473]\tvalid_0's multi_logloss: 0.815372\n",
      "[474]\tvalid_0's multi_logloss: 0.815337\n",
      "[475]\tvalid_0's multi_logloss: 0.815169\n",
      "[476]\tvalid_0's multi_logloss: 0.815181\n",
      "[477]\tvalid_0's multi_logloss: 0.814995\n",
      "[478]\tvalid_0's multi_logloss: 0.815022\n",
      "[479]\tvalid_0's multi_logloss: 0.814971\n",
      "[480]\tvalid_0's multi_logloss: 0.815015\n",
      "[481]\tvalid_0's multi_logloss: 0.814988\n",
      "[482]\tvalid_0's multi_logloss: 0.814981\n",
      "[483]\tvalid_0's multi_logloss: 0.814947\n",
      "[484]\tvalid_0's multi_logloss: 0.814951\n",
      "[485]\tvalid_0's multi_logloss: 0.814901\n",
      "[486]\tvalid_0's multi_logloss: 0.814868\n",
      "[487]\tvalid_0's multi_logloss: 0.814848\n",
      "[488]\tvalid_0's multi_logloss: 0.814863\n",
      "[489]\tvalid_0's multi_logloss: 0.814729\n",
      "[490]\tvalid_0's multi_logloss: 0.814609\n",
      "[491]\tvalid_0's multi_logloss: 0.814525\n",
      "[492]\tvalid_0's multi_logloss: 0.814432\n",
      "[493]\tvalid_0's multi_logloss: 0.814368\n",
      "[494]\tvalid_0's multi_logloss: 0.814309\n",
      "[495]\tvalid_0's multi_logloss: 0.814258\n",
      "[496]\tvalid_0's multi_logloss: 0.814194\n",
      "[497]\tvalid_0's multi_logloss: 0.81411\n",
      "[498]\tvalid_0's multi_logloss: 0.814024\n",
      "[499]\tvalid_0's multi_logloss: 0.814054\n",
      "[500]\tvalid_0's multi_logloss: 0.813981\n",
      "[501]\tvalid_0's multi_logloss: 0.814029\n",
      "[502]\tvalid_0's multi_logloss: 0.814038\n",
      "[503]\tvalid_0's multi_logloss: 0.813832\n",
      "[504]\tvalid_0's multi_logloss: 0.813866\n",
      "[505]\tvalid_0's multi_logloss: 0.813679\n",
      "[506]\tvalid_0's multi_logloss: 0.813574\n",
      "[507]\tvalid_0's multi_logloss: 0.813423\n",
      "[508]\tvalid_0's multi_logloss: 0.813311\n",
      "[509]\tvalid_0's multi_logloss: 0.813231\n",
      "[510]\tvalid_0's multi_logloss: 0.813118\n",
      "[511]\tvalid_0's multi_logloss: 0.812858\n",
      "[512]\tvalid_0's multi_logloss: 0.812614\n",
      "[513]\tvalid_0's multi_logloss: 0.81258\n",
      "[514]\tvalid_0's multi_logloss: 0.812496\n",
      "[515]\tvalid_0's multi_logloss: 0.812412\n",
      "[516]\tvalid_0's multi_logloss: 0.812351\n",
      "[517]\tvalid_0's multi_logloss: 0.812457\n",
      "[518]\tvalid_0's multi_logloss: 0.812421\n",
      "[519]\tvalid_0's multi_logloss: 0.812351\n",
      "[520]\tvalid_0's multi_logloss: 0.812371\n",
      "[521]\tvalid_0's multi_logloss: 0.812299\n",
      "[522]\tvalid_0's multi_logloss: 0.812226\n",
      "[523]\tvalid_0's multi_logloss: 0.812302\n",
      "[524]\tvalid_0's multi_logloss: 0.812264\n",
      "[525]\tvalid_0's multi_logloss: 0.812229\n",
      "[526]\tvalid_0's multi_logloss: 0.812142\n",
      "[527]\tvalid_0's multi_logloss: 0.81209\n",
      "[528]\tvalid_0's multi_logloss: 0.812114\n",
      "[529]\tvalid_0's multi_logloss: 0.811985\n",
      "[530]\tvalid_0's multi_logloss: 0.811922\n",
      "[531]\tvalid_0's multi_logloss: 0.811865\n",
      "[532]\tvalid_0's multi_logloss: 0.81182\n",
      "[533]\tvalid_0's multi_logloss: 0.811743\n",
      "[534]\tvalid_0's multi_logloss: 0.811746\n",
      "[535]\tvalid_0's multi_logloss: 0.811694\n",
      "[536]\tvalid_0's multi_logloss: 0.811614\n",
      "[537]\tvalid_0's multi_logloss: 0.811582\n",
      "[538]\tvalid_0's multi_logloss: 0.811488\n",
      "[539]\tvalid_0's multi_logloss: 0.811508\n",
      "[540]\tvalid_0's multi_logloss: 0.811571\n",
      "[541]\tvalid_0's multi_logloss: 0.811402\n",
      "[542]\tvalid_0's multi_logloss: 0.811245\n",
      "[543]\tvalid_0's multi_logloss: 0.811309\n",
      "[544]\tvalid_0's multi_logloss: 0.811272\n",
      "[545]\tvalid_0's multi_logloss: 0.811307\n",
      "[546]\tvalid_0's multi_logloss: 0.811265\n",
      "[547]\tvalid_0's multi_logloss: 0.811135\n",
      "[548]\tvalid_0's multi_logloss: 0.811071\n",
      "[549]\tvalid_0's multi_logloss: 0.811065\n",
      "[550]\tvalid_0's multi_logloss: 0.810973\n",
      "[551]\tvalid_0's multi_logloss: 0.810965\n",
      "[552]\tvalid_0's multi_logloss: 0.81096\n",
      "[553]\tvalid_0's multi_logloss: 0.810773\n",
      "[554]\tvalid_0's multi_logloss: 0.810674\n",
      "[555]\tvalid_0's multi_logloss: 0.81069\n",
      "[556]\tvalid_0's multi_logloss: 0.810599\n",
      "[557]\tvalid_0's multi_logloss: 0.810522\n",
      "[558]\tvalid_0's multi_logloss: 0.81046\n",
      "[559]\tvalid_0's multi_logloss: 0.810424\n",
      "[560]\tvalid_0's multi_logloss: 0.810376\n",
      "[561]\tvalid_0's multi_logloss: 0.810271\n",
      "[562]\tvalid_0's multi_logloss: 0.810086\n",
      "[563]\tvalid_0's multi_logloss: 0.810124\n",
      "[564]\tvalid_0's multi_logloss: 0.810169\n",
      "[565]\tvalid_0's multi_logloss: 0.80994\n",
      "[566]\tvalid_0's multi_logloss: 0.809876\n",
      "[567]\tvalid_0's multi_logloss: 0.809827\n",
      "[568]\tvalid_0's multi_logloss: 0.809781\n",
      "[569]\tvalid_0's multi_logloss: 0.809745\n",
      "[570]\tvalid_0's multi_logloss: 0.809789\n",
      "[571]\tvalid_0's multi_logloss: 0.809781\n",
      "[572]\tvalid_0's multi_logloss: 0.809656\n",
      "[573]\tvalid_0's multi_logloss: 0.809653\n",
      "[574]\tvalid_0's multi_logloss: 0.809612\n",
      "[575]\tvalid_0's multi_logloss: 0.809463\n",
      "[576]\tvalid_0's multi_logloss: 0.809449\n",
      "[577]\tvalid_0's multi_logloss: 0.809401\n",
      "[578]\tvalid_0's multi_logloss: 0.8094\n",
      "[579]\tvalid_0's multi_logloss: 0.809393\n",
      "[580]\tvalid_0's multi_logloss: 0.80942\n",
      "[581]\tvalid_0's multi_logloss: 0.809351\n",
      "[582]\tvalid_0's multi_logloss: 0.809399\n",
      "[583]\tvalid_0's multi_logloss: 0.809403\n",
      "[584]\tvalid_0's multi_logloss: 0.809489\n",
      "[585]\tvalid_0's multi_logloss: 0.809497\n",
      "[586]\tvalid_0's multi_logloss: 0.809503\n",
      "[587]\tvalid_0's multi_logloss: 0.809568\n",
      "[588]\tvalid_0's multi_logloss: 0.809616\n",
      "[589]\tvalid_0's multi_logloss: 0.809598\n",
      "[590]\tvalid_0's multi_logloss: 0.809532\n",
      "[591]\tvalid_0's multi_logloss: 0.809474\n",
      "[592]\tvalid_0's multi_logloss: 0.809498\n",
      "[593]\tvalid_0's multi_logloss: 0.809439\n",
      "[594]\tvalid_0's multi_logloss: 0.809421\n",
      "[595]\tvalid_0's multi_logloss: 0.809469\n",
      "[596]\tvalid_0's multi_logloss: 0.809481\n",
      "[597]\tvalid_0's multi_logloss: 0.809344\n",
      "[598]\tvalid_0's multi_logloss: 0.809241\n",
      "[599]\tvalid_0's multi_logloss: 0.809305\n",
      "[600]\tvalid_0's multi_logloss: 0.809298\n",
      "[601]\tvalid_0's multi_logloss: 0.809217\n",
      "[602]\tvalid_0's multi_logloss: 0.809196\n",
      "[603]\tvalid_0's multi_logloss: 0.809151\n",
      "[604]\tvalid_0's multi_logloss: 0.809251\n",
      "[605]\tvalid_0's multi_logloss: 0.809253\n",
      "[606]\tvalid_0's multi_logloss: 0.809225\n",
      "[607]\tvalid_0's multi_logloss: 0.809238\n",
      "[608]\tvalid_0's multi_logloss: 0.809219\n",
      "[609]\tvalid_0's multi_logloss: 0.809013\n",
      "[610]\tvalid_0's multi_logloss: 0.809043\n",
      "[611]\tvalid_0's multi_logloss: 0.808995\n",
      "[612]\tvalid_0's multi_logloss: 0.809002\n",
      "[613]\tvalid_0's multi_logloss: 0.808998\n",
      "[614]\tvalid_0's multi_logloss: 0.809053\n",
      "[615]\tvalid_0's multi_logloss: 0.808942\n",
      "[616]\tvalid_0's multi_logloss: 0.80901\n",
      "[617]\tvalid_0's multi_logloss: 0.809064\n",
      "[618]\tvalid_0's multi_logloss: 0.80897\n",
      "[619]\tvalid_0's multi_logloss: 0.808994\n",
      "[620]\tvalid_0's multi_logloss: 0.808985\n",
      "[621]\tvalid_0's multi_logloss: 0.808888\n",
      "[622]\tvalid_0's multi_logloss: 0.808926\n",
      "[623]\tvalid_0's multi_logloss: 0.808836\n",
      "[624]\tvalid_0's multi_logloss: 0.80884\n",
      "[625]\tvalid_0's multi_logloss: 0.808842\n",
      "[626]\tvalid_0's multi_logloss: 0.808916\n",
      "[627]\tvalid_0's multi_logloss: 0.808913\n",
      "[628]\tvalid_0's multi_logloss: 0.808917\n",
      "[629]\tvalid_0's multi_logloss: 0.808747\n",
      "[630]\tvalid_0's multi_logloss: 0.808684\n",
      "[631]\tvalid_0's multi_logloss: 0.808651\n",
      "[632]\tvalid_0's multi_logloss: 0.808628\n",
      "[633]\tvalid_0's multi_logloss: 0.808591\n",
      "[634]\tvalid_0's multi_logloss: 0.808525\n",
      "[635]\tvalid_0's multi_logloss: 0.808481\n",
      "[636]\tvalid_0's multi_logloss: 0.808494\n",
      "[637]\tvalid_0's multi_logloss: 0.808459\n",
      "[638]\tvalid_0's multi_logloss: 0.808493\n",
      "[639]\tvalid_0's multi_logloss: 0.808502\n",
      "[640]\tvalid_0's multi_logloss: 0.808447\n",
      "[641]\tvalid_0's multi_logloss: 0.808523\n",
      "[642]\tvalid_0's multi_logloss: 0.808497\n",
      "[643]\tvalid_0's multi_logloss: 0.808532\n",
      "[644]\tvalid_0's multi_logloss: 0.808493\n",
      "[645]\tvalid_0's multi_logloss: 0.808393\n",
      "[646]\tvalid_0's multi_logloss: 0.808322\n",
      "[647]\tvalid_0's multi_logloss: 0.808392\n",
      "[648]\tvalid_0's multi_logloss: 0.808292\n",
      "[649]\tvalid_0's multi_logloss: 0.808235\n",
      "[650]\tvalid_0's multi_logloss: 0.808219\n",
      "[651]\tvalid_0's multi_logloss: 0.808198\n",
      "[652]\tvalid_0's multi_logloss: 0.808144\n",
      "[653]\tvalid_0's multi_logloss: 0.808123\n",
      "[654]\tvalid_0's multi_logloss: 0.808171\n",
      "[655]\tvalid_0's multi_logloss: 0.808208\n",
      "[656]\tvalid_0's multi_logloss: 0.808149\n",
      "[657]\tvalid_0's multi_logloss: 0.808153\n",
      "[658]\tvalid_0's multi_logloss: 0.8082\n",
      "[659]\tvalid_0's multi_logloss: 0.808216\n",
      "[660]\tvalid_0's multi_logloss: 0.808175\n",
      "[661]\tvalid_0's multi_logloss: 0.80811\n",
      "[662]\tvalid_0's multi_logloss: 0.808108\n",
      "[663]\tvalid_0's multi_logloss: 0.808029\n",
      "[664]\tvalid_0's multi_logloss: 0.807968\n",
      "[665]\tvalid_0's multi_logloss: 0.807981\n",
      "[666]\tvalid_0's multi_logloss: 0.807908\n",
      "[667]\tvalid_0's multi_logloss: 0.807922\n",
      "[668]\tvalid_0's multi_logloss: 0.807912\n",
      "[669]\tvalid_0's multi_logloss: 0.807861\n",
      "[670]\tvalid_0's multi_logloss: 0.807783\n",
      "[671]\tvalid_0's multi_logloss: 0.807754\n",
      "[672]\tvalid_0's multi_logloss: 0.80774\n",
      "[673]\tvalid_0's multi_logloss: 0.807788\n",
      "[674]\tvalid_0's multi_logloss: 0.807731\n",
      "[675]\tvalid_0's multi_logloss: 0.807712\n",
      "[676]\tvalid_0's multi_logloss: 0.807752\n",
      "[677]\tvalid_0's multi_logloss: 0.807722\n",
      "[678]\tvalid_0's multi_logloss: 0.807724\n",
      "[679]\tvalid_0's multi_logloss: 0.807703\n",
      "[680]\tvalid_0's multi_logloss: 0.80762\n",
      "[681]\tvalid_0's multi_logloss: 0.807529\n",
      "[682]\tvalid_0's multi_logloss: 0.807458\n",
      "[683]\tvalid_0's multi_logloss: 0.807601\n",
      "[684]\tvalid_0's multi_logloss: 0.807696\n",
      "[685]\tvalid_0's multi_logloss: 0.807673\n",
      "[686]\tvalid_0's multi_logloss: 0.807627\n",
      "[687]\tvalid_0's multi_logloss: 0.807648\n",
      "[688]\tvalid_0's multi_logloss: 0.807576\n",
      "[689]\tvalid_0's multi_logloss: 0.80763\n",
      "[690]\tvalid_0's multi_logloss: 0.807622\n",
      "[691]\tvalid_0's multi_logloss: 0.807678\n",
      "[692]\tvalid_0's multi_logloss: 0.80764\n",
      "[693]\tvalid_0's multi_logloss: 0.807658\n",
      "[694]\tvalid_0's multi_logloss: 0.807714\n",
      "[695]\tvalid_0's multi_logloss: 0.807747\n",
      "[696]\tvalid_0's multi_logloss: 0.807657\n",
      "[697]\tvalid_0's multi_logloss: 0.807608\n",
      "[698]\tvalid_0's multi_logloss: 0.807622\n",
      "[699]\tvalid_0's multi_logloss: 0.807672\n",
      "[700]\tvalid_0's multi_logloss: 0.80763\n",
      "[701]\tvalid_0's multi_logloss: 0.807585\n",
      "[702]\tvalid_0's multi_logloss: 0.807544\n",
      "[703]\tvalid_0's multi_logloss: 0.807571\n",
      "[704]\tvalid_0's multi_logloss: 0.807595\n",
      "[705]\tvalid_0's multi_logloss: 0.807543\n",
      "[706]\tvalid_0's multi_logloss: 0.80763\n",
      "[707]\tvalid_0's multi_logloss: 0.807593\n",
      "[708]\tvalid_0's multi_logloss: 0.807557\n",
      "[709]\tvalid_0's multi_logloss: 0.807633\n",
      "[710]\tvalid_0's multi_logloss: 0.807636\n",
      "[711]\tvalid_0's multi_logloss: 0.807637\n",
      "[712]\tvalid_0's multi_logloss: 0.807613\n",
      "[713]\tvalid_0's multi_logloss: 0.807696\n",
      "[714]\tvalid_0's multi_logloss: 0.807733\n",
      "[715]\tvalid_0's multi_logloss: 0.807705\n",
      "[716]\tvalid_0's multi_logloss: 0.807741\n",
      "[717]\tvalid_0's multi_logloss: 0.807732\n",
      "[718]\tvalid_0's multi_logloss: 0.807636\n",
      "[719]\tvalid_0's multi_logloss: 0.807722\n",
      "[720]\tvalid_0's multi_logloss: 0.80762\n",
      "[721]\tvalid_0's multi_logloss: 0.807567\n",
      "[722]\tvalid_0's multi_logloss: 0.807601\n",
      "[723]\tvalid_0's multi_logloss: 0.807547\n",
      "[724]\tvalid_0's multi_logloss: 0.807612\n",
      "[725]\tvalid_0's multi_logloss: 0.807602\n",
      "[726]\tvalid_0's multi_logloss: 0.807726\n",
      "[727]\tvalid_0's multi_logloss: 0.807721\n",
      "[728]\tvalid_0's multi_logloss: 0.807723\n",
      "[729]\tvalid_0's multi_logloss: 0.807783\n",
      "[730]\tvalid_0's multi_logloss: 0.807863\n",
      "[731]\tvalid_0's multi_logloss: 0.807847\n",
      "[732]\tvalid_0's multi_logloss: 0.807924\n",
      "[733]\tvalid_0's multi_logloss: 0.807751\n",
      "[734]\tvalid_0's multi_logloss: 0.80769\n",
      "[735]\tvalid_0's multi_logloss: 0.807723\n",
      "[736]\tvalid_0's multi_logloss: 0.807738\n",
      "[737]\tvalid_0's multi_logloss: 0.807655\n",
      "[738]\tvalid_0's multi_logloss: 0.807663\n",
      "[739]\tvalid_0's multi_logloss: 0.807676\n",
      "[740]\tvalid_0's multi_logloss: 0.807676\n",
      "[741]\tvalid_0's multi_logloss: 0.807706\n",
      "[742]\tvalid_0's multi_logloss: 0.807734\n",
      "[743]\tvalid_0's multi_logloss: 0.807783\n",
      "[744]\tvalid_0's multi_logloss: 0.807845\n",
      "[745]\tvalid_0's multi_logloss: 0.807785\n",
      "[746]\tvalid_0's multi_logloss: 0.807834\n",
      "[747]\tvalid_0's multi_logloss: 0.807791\n",
      "[748]\tvalid_0's multi_logloss: 0.807801\n",
      "[749]\tvalid_0's multi_logloss: 0.807833\n",
      "[750]\tvalid_0's multi_logloss: 0.807838\n",
      "[751]\tvalid_0's multi_logloss: 0.807823\n",
      "[752]\tvalid_0's multi_logloss: 0.807854\n",
      "[753]\tvalid_0's multi_logloss: 0.807872\n",
      "[754]\tvalid_0's multi_logloss: 0.807931\n",
      "[755]\tvalid_0's multi_logloss: 0.807989\n",
      "[756]\tvalid_0's multi_logloss: 0.808102\n",
      "[757]\tvalid_0's multi_logloss: 0.808126\n",
      "[758]\tvalid_0's multi_logloss: 0.808218\n",
      "[759]\tvalid_0's multi_logloss: 0.808249\n",
      "[760]\tvalid_0's multi_logloss: 0.808348\n",
      "[761]\tvalid_0's multi_logloss: 0.808379\n",
      "[762]\tvalid_0's multi_logloss: 0.808485\n",
      "[763]\tvalid_0's multi_logloss: 0.808496\n",
      "[764]\tvalid_0's multi_logloss: 0.808559\n",
      "[765]\tvalid_0's multi_logloss: 0.808599\n",
      "[766]\tvalid_0's multi_logloss: 0.808608\n",
      "[767]\tvalid_0's multi_logloss: 0.808565\n",
      "[768]\tvalid_0's multi_logloss: 0.808507\n",
      "[769]\tvalid_0's multi_logloss: 0.808383\n",
      "[770]\tvalid_0's multi_logloss: 0.808384\n",
      "[771]\tvalid_0's multi_logloss: 0.808433\n",
      "[772]\tvalid_0's multi_logloss: 0.808422\n",
      "[773]\tvalid_0's multi_logloss: 0.808379\n",
      "[774]\tvalid_0's multi_logloss: 0.808392\n",
      "[775]\tvalid_0's multi_logloss: 0.808372\n",
      "[776]\tvalid_0's multi_logloss: 0.808367\n",
      "[777]\tvalid_0's multi_logloss: 0.808284\n",
      "[778]\tvalid_0's multi_logloss: 0.808229\n",
      "[779]\tvalid_0's multi_logloss: 0.808307\n",
      "[780]\tvalid_0's multi_logloss: 0.808297\n",
      "[781]\tvalid_0's multi_logloss: 0.80824\n",
      "[782]\tvalid_0's multi_logloss: 0.808306\n",
      "[783]\tvalid_0's multi_logloss: 0.808357\n",
      "[784]\tvalid_0's multi_logloss: 0.808306\n",
      "[785]\tvalid_0's multi_logloss: 0.80836\n",
      "[786]\tvalid_0's multi_logloss: 0.808462\n",
      "[787]\tvalid_0's multi_logloss: 0.808529\n",
      "[788]\tvalid_0's multi_logloss: 0.808565\n",
      "[789]\tvalid_0's multi_logloss: 0.808641\n",
      "[790]\tvalid_0's multi_logloss: 0.80865\n",
      "[791]\tvalid_0's multi_logloss: 0.808647\n",
      "[792]\tvalid_0's multi_logloss: 0.80872\n",
      "[793]\tvalid_0's multi_logloss: 0.808734\n",
      "[794]\tvalid_0's multi_logloss: 0.808713\n",
      "[795]\tvalid_0's multi_logloss: 0.808726\n",
      "[796]\tvalid_0's multi_logloss: 0.808796\n",
      "[797]\tvalid_0's multi_logloss: 0.808858\n",
      "[798]\tvalid_0's multi_logloss: 0.808942\n",
      "[799]\tvalid_0's multi_logloss: 0.80885\n",
      "[800]\tvalid_0's multi_logloss: 0.808929\n",
      "[801]\tvalid_0's multi_logloss: 0.808999\n",
      "[802]\tvalid_0's multi_logloss: 0.808976\n",
      "[803]\tvalid_0's multi_logloss: 0.808961\n",
      "[804]\tvalid_0's multi_logloss: 0.808946\n",
      "[805]\tvalid_0's multi_logloss: 0.808947\n",
      "[806]\tvalid_0's multi_logloss: 0.809018\n",
      "[807]\tvalid_0's multi_logloss: 0.809068\n",
      "[808]\tvalid_0's multi_logloss: 0.808994\n",
      "[809]\tvalid_0's multi_logloss: 0.809055\n",
      "[810]\tvalid_0's multi_logloss: 0.809001\n",
      "[811]\tvalid_0's multi_logloss: 0.809015\n",
      "[812]\tvalid_0's multi_logloss: 0.809001\n",
      "[813]\tvalid_0's multi_logloss: 0.809012\n",
      "[814]\tvalid_0's multi_logloss: 0.809103\n",
      "[815]\tvalid_0's multi_logloss: 0.809232\n",
      "[816]\tvalid_0's multi_logloss: 0.80928\n",
      "[817]\tvalid_0's multi_logloss: 0.809395\n",
      "[818]\tvalid_0's multi_logloss: 0.809424\n",
      "[819]\tvalid_0's multi_logloss: 0.809482\n",
      "[820]\tvalid_0's multi_logloss: 0.809489\n",
      "[821]\tvalid_0's multi_logloss: 0.809576\n",
      "[822]\tvalid_0's multi_logloss: 0.80958\n",
      "[823]\tvalid_0's multi_logloss: 0.809621\n",
      "[824]\tvalid_0's multi_logloss: 0.809652\n",
      "[825]\tvalid_0's multi_logloss: 0.809688\n",
      "[826]\tvalid_0's multi_logloss: 0.809607\n",
      "[827]\tvalid_0's multi_logloss: 0.809656\n",
      "[828]\tvalid_0's multi_logloss: 0.809679\n",
      "[829]\tvalid_0's multi_logloss: 0.809678\n",
      "[830]\tvalid_0's multi_logloss: 0.809763\n",
      "[831]\tvalid_0's multi_logloss: 0.809766\n",
      "[832]\tvalid_0's multi_logloss: 0.809776\n",
      "[833]\tvalid_0's multi_logloss: 0.809764\n",
      "[834]\tvalid_0's multi_logloss: 0.809782\n",
      "[835]\tvalid_0's multi_logloss: 0.809923\n",
      "[836]\tvalid_0's multi_logloss: 0.809893\n",
      "[837]\tvalid_0's multi_logloss: 0.810075\n",
      "[838]\tvalid_0's multi_logloss: 0.810095\n",
      "[839]\tvalid_0's multi_logloss: 0.810144\n",
      "[840]\tvalid_0's multi_logloss: 0.810118\n",
      "[841]\tvalid_0's multi_logloss: 0.810198\n",
      "[842]\tvalid_0's multi_logloss: 0.810211\n",
      "[843]\tvalid_0's multi_logloss: 0.810238\n",
      "[844]\tvalid_0's multi_logloss: 0.810303\n",
      "[845]\tvalid_0's multi_logloss: 0.810435\n",
      "[846]\tvalid_0's multi_logloss: 0.810442\n",
      "[847]\tvalid_0's multi_logloss: 0.810502\n",
      "[848]\tvalid_0's multi_logloss: 0.810502\n",
      "[849]\tvalid_0's multi_logloss: 0.810579\n",
      "[850]\tvalid_0's multi_logloss: 0.81064\n",
      "[851]\tvalid_0's multi_logloss: 0.810688\n",
      "[852]\tvalid_0's multi_logloss: 0.810748\n",
      "[853]\tvalid_0's multi_logloss: 0.810812\n",
      "[854]\tvalid_0's multi_logloss: 0.810835\n",
      "[855]\tvalid_0's multi_logloss: 0.81098\n",
      "[856]\tvalid_0's multi_logloss: 0.810964\n",
      "[857]\tvalid_0's multi_logloss: 0.810995\n",
      "[858]\tvalid_0's multi_logloss: 0.810997\n",
      "[859]\tvalid_0's multi_logloss: 0.810997\n",
      "[860]\tvalid_0's multi_logloss: 0.811035\n",
      "[861]\tvalid_0's multi_logloss: 0.811069\n",
      "[862]\tvalid_0's multi_logloss: 0.811057\n",
      "[863]\tvalid_0's multi_logloss: 0.811104\n",
      "[864]\tvalid_0's multi_logloss: 0.811153\n",
      "[865]\tvalid_0's multi_logloss: 0.811178\n",
      "[866]\tvalid_0's multi_logloss: 0.811192\n",
      "[867]\tvalid_0's multi_logloss: 0.811218\n",
      "[868]\tvalid_0's multi_logloss: 0.81123\n",
      "[869]\tvalid_0's multi_logloss: 0.811197\n",
      "[870]\tvalid_0's multi_logloss: 0.811307\n",
      "[871]\tvalid_0's multi_logloss: 0.811417\n",
      "[872]\tvalid_0's multi_logloss: 0.811489\n",
      "[873]\tvalid_0's multi_logloss: 0.811532\n",
      "[874]\tvalid_0's multi_logloss: 0.811582\n",
      "[875]\tvalid_0's multi_logloss: 0.811694\n",
      "[876]\tvalid_0's multi_logloss: 0.811802\n",
      "[877]\tvalid_0's multi_logloss: 0.811771\n",
      "[878]\tvalid_0's multi_logloss: 0.811742\n",
      "[879]\tvalid_0's multi_logloss: 0.81177\n",
      "[880]\tvalid_0's multi_logloss: 0.811752\n",
      "[881]\tvalid_0's multi_logloss: 0.811802\n",
      "[882]\tvalid_0's multi_logloss: 0.811813\n",
      "[883]\tvalid_0's multi_logloss: 0.811773\n",
      "[884]\tvalid_0's multi_logloss: 0.811668\n",
      "[885]\tvalid_0's multi_logloss: 0.811683\n",
      "[886]\tvalid_0's multi_logloss: 0.811723\n",
      "[887]\tvalid_0's multi_logloss: 0.811752\n",
      "[888]\tvalid_0's multi_logloss: 0.811811\n",
      "[889]\tvalid_0's multi_logloss: 0.811849\n",
      "[890]\tvalid_0's multi_logloss: 0.811867\n",
      "[891]\tvalid_0's multi_logloss: 0.811811\n",
      "[892]\tvalid_0's multi_logloss: 0.811873\n",
      "[893]\tvalid_0's multi_logloss: 0.812016\n",
      "[894]\tvalid_0's multi_logloss: 0.812153\n",
      "[895]\tvalid_0's multi_logloss: 0.812216\n",
      "[896]\tvalid_0's multi_logloss: 0.812316\n",
      "[897]\tvalid_0's multi_logloss: 0.812269\n",
      "[898]\tvalid_0's multi_logloss: 0.812294\n",
      "[899]\tvalid_0's multi_logloss: 0.812376\n",
      "[900]\tvalid_0's multi_logloss: 0.8124\n",
      "[901]\tvalid_0's multi_logloss: 0.812558\n",
      "[902]\tvalid_0's multi_logloss: 0.812603\n",
      "[903]\tvalid_0's multi_logloss: 0.812636\n",
      "[904]\tvalid_0's multi_logloss: 0.812708\n",
      "[905]\tvalid_0's multi_logloss: 0.812795\n",
      "[906]\tvalid_0's multi_logloss: 0.812918\n",
      "[907]\tvalid_0's multi_logloss: 0.812942\n",
      "[908]\tvalid_0's multi_logloss: 0.812907\n",
      "[909]\tvalid_0's multi_logloss: 0.812855\n",
      "[910]\tvalid_0's multi_logloss: 0.812903\n",
      "[911]\tvalid_0's multi_logloss: 0.812967\n",
      "[912]\tvalid_0's multi_logloss: 0.813009\n",
      "[913]\tvalid_0's multi_logloss: 0.812867\n",
      "[914]\tvalid_0's multi_logloss: 0.812887\n",
      "[915]\tvalid_0's multi_logloss: 0.812838\n",
      "[916]\tvalid_0's multi_logloss: 0.812846\n",
      "[917]\tvalid_0's multi_logloss: 0.812867\n",
      "[918]\tvalid_0's multi_logloss: 0.812895\n",
      "[919]\tvalid_0's multi_logloss: 0.813055\n",
      "[920]\tvalid_0's multi_logloss: 0.813125\n",
      "[921]\tvalid_0's multi_logloss: 0.813228\n",
      "[922]\tvalid_0's multi_logloss: 0.813259\n",
      "[923]\tvalid_0's multi_logloss: 0.813296\n",
      "[924]\tvalid_0's multi_logloss: 0.813344\n",
      "[925]\tvalid_0's multi_logloss: 0.813381\n",
      "[926]\tvalid_0's multi_logloss: 0.813339\n",
      "[927]\tvalid_0's multi_logloss: 0.813391\n",
      "[928]\tvalid_0's multi_logloss: 0.813459\n",
      "[929]\tvalid_0's multi_logloss: 0.813461\n",
      "[930]\tvalid_0's multi_logloss: 0.813569\n",
      "[931]\tvalid_0's multi_logloss: 0.813531\n",
      "[932]\tvalid_0's multi_logloss: 0.813598\n",
      "[933]\tvalid_0's multi_logloss: 0.813591\n",
      "[934]\tvalid_0's multi_logloss: 0.81379\n",
      "[935]\tvalid_0's multi_logloss: 0.813804\n",
      "[936]\tvalid_0's multi_logloss: 0.813767\n",
      "[937]\tvalid_0's multi_logloss: 0.813742\n",
      "[938]\tvalid_0's multi_logloss: 0.813788\n",
      "[939]\tvalid_0's multi_logloss: 0.813772\n",
      "[940]\tvalid_0's multi_logloss: 0.813795\n",
      "[941]\tvalid_0's multi_logloss: 0.813893\n",
      "[942]\tvalid_0's multi_logloss: 0.813831\n",
      "[943]\tvalid_0's multi_logloss: 0.813886\n",
      "[944]\tvalid_0's multi_logloss: 0.813899\n",
      "[945]\tvalid_0's multi_logloss: 0.813937\n",
      "[946]\tvalid_0's multi_logloss: 0.813884\n",
      "[947]\tvalid_0's multi_logloss: 0.813908\n",
      "[948]\tvalid_0's multi_logloss: 0.81388\n",
      "[949]\tvalid_0's multi_logloss: 0.813843\n",
      "[950]\tvalid_0's multi_logloss: 0.813812\n",
      "[951]\tvalid_0's multi_logloss: 0.813825\n",
      "[952]\tvalid_0's multi_logloss: 0.813869\n",
      "[953]\tvalid_0's multi_logloss: 0.813963\n",
      "[954]\tvalid_0's multi_logloss: 0.813991\n",
      "[955]\tvalid_0's multi_logloss: 0.814033\n",
      "[956]\tvalid_0's multi_logloss: 0.813998\n",
      "[957]\tvalid_0's multi_logloss: 0.813998\n",
      "[958]\tvalid_0's multi_logloss: 0.814013\n",
      "[959]\tvalid_0's multi_logloss: 0.814003\n",
      "[960]\tvalid_0's multi_logloss: 0.814075\n",
      "[961]\tvalid_0's multi_logloss: 0.814199\n",
      "[962]\tvalid_0's multi_logloss: 0.814321\n",
      "[963]\tvalid_0's multi_logloss: 0.814274\n",
      "[964]\tvalid_0's multi_logloss: 0.814372\n",
      "[965]\tvalid_0's multi_logloss: 0.81448\n",
      "[966]\tvalid_0's multi_logloss: 0.814514\n",
      "[967]\tvalid_0's multi_logloss: 0.814515\n",
      "[968]\tvalid_0's multi_logloss: 0.814445\n",
      "[969]\tvalid_0's multi_logloss: 0.814446\n",
      "[970]\tvalid_0's multi_logloss: 0.814523\n",
      "[971]\tvalid_0's multi_logloss: 0.814609\n",
      "[972]\tvalid_0's multi_logloss: 0.814606\n",
      "[973]\tvalid_0's multi_logloss: 0.814649\n",
      "[974]\tvalid_0's multi_logloss: 0.814678\n",
      "[975]\tvalid_0's multi_logloss: 0.814785\n",
      "[976]\tvalid_0's multi_logloss: 0.814906\n",
      "[977]\tvalid_0's multi_logloss: 0.814938\n",
      "[978]\tvalid_0's multi_logloss: 0.814986\n",
      "[979]\tvalid_0's multi_logloss: 0.814994\n",
      "[980]\tvalid_0's multi_logloss: 0.815081\n",
      "[981]\tvalid_0's multi_logloss: 0.81516\n",
      "[982]\tvalid_0's multi_logloss: 0.815258\n",
      "[983]\tvalid_0's multi_logloss: 0.81525\n",
      "[984]\tvalid_0's multi_logloss: 0.815289\n",
      "[985]\tvalid_0's multi_logloss: 0.815329\n",
      "[986]\tvalid_0's multi_logloss: 0.815413\n",
      "[987]\tvalid_0's multi_logloss: 0.815487\n",
      "[988]\tvalid_0's multi_logloss: 0.815466\n",
      "[989]\tvalid_0's multi_logloss: 0.815502\n",
      "[990]\tvalid_0's multi_logloss: 0.815527\n",
      "[991]\tvalid_0's multi_logloss: 0.815535\n",
      "[992]\tvalid_0's multi_logloss: 0.815574\n",
      "[993]\tvalid_0's multi_logloss: 0.815629\n",
      "[994]\tvalid_0's multi_logloss: 0.815634\n",
      "[995]\tvalid_0's multi_logloss: 0.815665\n",
      "[996]\tvalid_0's multi_logloss: 0.815714\n",
      "[997]\tvalid_0's multi_logloss: 0.815758\n",
      "[998]\tvalid_0's multi_logloss: 0.815791\n",
      "[999]\tvalid_0's multi_logloss: 0.81586\n",
      "[1000]\tvalid_0's multi_logloss: 0.815951\n",
      "정확도:0.728722,정밀도:0.729000,    재현율:0.729000,f1:0.729000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm_wrapper = LGBMClassifier(n_estimators=1000)\n",
    "evals=[(X_test,y_test)]\n",
    "lgbm_wrapper.fit(X_train, y_train, early_stopping_rounds=1000, eval_metric='logloss', eval_set=evals, verbose=True)\n",
    "preds = lgbm_wrapper.predict(X_test)\n",
    "## n_ estimator 가 200을 넘어가면 오히려 loss 가 증가하는 경향을 보여서 100으로 설정\n",
    "def get_clf_eval(y_test,pred = None,pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = round(precision_score(y_test, pred, average='micro'), ndigits=3)\n",
    "    recall = round(recall_score(y_test, pred, average='micro'), ndigits=3)\n",
    "    f1 = round(f1_score(y_test, pred, average='micro'), ndigits=3)\n",
    "    print('정확도:{0:,f},정밀도:{1:f},\\\n",
    "    재현율:{2:f},f1:{3:f}'.format(accuracy,precision,recall,f1),'\\n')\n",
    "# 모델 평가 지표 함수\n",
    "pred_proba = lgbm_wrapper.predict_proba(X_test)[:,1]\n",
    "get_clf_eval(y_test,preds,pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.7473898345648727\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame()\n",
    "list=os.listdir('./total/')\n",
    "for list in list:\n",
    "    df1= pd.read_csv('./total/{}'.format(list))\n",
    "    df1=df1[['action','macc_x_mean','e4acc_x_mean','macc_y_mean','e4acc_y_mean','macc_z_mean','e4acc_z_mean']]\n",
    "    df=pd.concat([df,df1])\n",
    "df[['e4acc_x_mean','e4acc_y_mean','e4acc_z_mean']] = df[['e4acc_x_mean','e4acc_y_mean','e4acc_z_mean']].fillna(df[['macc_x_mean','macc_y_mean','macc_z_mean']])\n",
    "\n",
    "df = df.dropna(subset=['macc_x_mean', 'e4acc_x_mean'], axis=0)\n",
    "df = df[(df['action']!='sleep')&(df['action']!='recreation_etc')&(df['action']!='meal')&(df['action']!='hobby')]\n",
    "X = df.drop(['action'], axis=1)\n",
    "y = df['action']\n",
    "\n",
    "\n",
    "## sleep은 추가적인 자료에 있고, 측정이 어렵기에 제거, recreation etc는 행위의 종류가 다양하여 제거 , 식사도 측정이 불가하다고 판단\n",
    "## 취미또한 한 테마안에 여러 활동이 포함되어 제거\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "\n",
    "## 수민님이 주신 scaler\n",
    "for col in X_train.columns:\n",
    "    scal = RobustScaler()\n",
    "    X_train[col] = scal.fit_transform(np.array(X_train[col]).reshape(-1, 1))\n",
    "    X_test[col] = scal.transform(np.array(X_test[col]).reshape(-1, 1))\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 400)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"정확도 : {}\".format(accuracy_score(y_test, y_pred)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
